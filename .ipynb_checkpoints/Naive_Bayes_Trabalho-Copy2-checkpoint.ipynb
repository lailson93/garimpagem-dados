{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes - Trabalho\n",
    "\n",
    "## Questão 1\n",
    "\n",
    "Implemente um classifacor Naive Bayes para o problema de predizer a qualidade de um carro. Para este fim, utilizaremos um conjunto de dados referente a qualidade de carros, disponível no [UCI](https://archive.ics.uci.edu/ml/datasets/car+evaluation). Este dataset de carros possui as seguintes features e classe:\n",
    "\n",
    "** Attributos **\n",
    "1. buying: vhigh, high, med, low\n",
    "2. maint: vhigh, high, med, low\n",
    "3. doors: 2, 3, 4, 5, more\n",
    "4. persons: 2, 4, more\n",
    "5. lug_boot: small, med, big\n",
    "6. safety: low, med, high\n",
    "\n",
    "([1, 1, 2, 5, 3, 1, 1])\n",
    "\n",
    "** Classes **\n",
    "1. unacc, acc, good, vgood\n",
    "\n",
    "## Questão 2\n",
    "Crie uma versão de sua implementação usando as funções disponíveis na biblioteca SciKitLearn para o Naive Bayes ([veja aqui](http://scikit-learn.org/stable/modules/naive_bayes.html)) \n",
    "\n",
    "## Questão 3\n",
    "\n",
    "Analise a acurácia dos dois algoritmos e discuta a sua solução."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "###QUESTAO 1#########\n",
    "################ RESOLUCAO ######################################\n",
    "#\n",
    "#    buying: vhigh, high, med, low\n",
    "#    maint: vhigh, high, med, low\n",
    "#    doors: 2, 3, 4, 5, more\n",
    "#    persons: 2, 4, more\n",
    "#    lug_boot: small, med, big\n",
    "#    safety: low, med, high\n",
    "#\n",
    "#   CAR                      car acceptability\n",
    "#   . PRICE                  overall price\n",
    "#   . . buying               buying price\n",
    "#   . . maint                price of the maintenance\n",
    "#   . TECH                   technical characteristics\n",
    "#   . . COMFORT              comfort\n",
    "#   . . . doors              number of doors\n",
    "#   . . . persons            capacity in terms of persons to carry\n",
    "#   . . . lug_boot           the size of luggage boot\n",
    "#   . . safety               estimated safety of the car\n",
    "#\n",
    "\n",
    "import pandas as pd\n",
    "filename='car.data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vhigh</th>\n",
       "      <th>vhigh.1</th>\n",
       "      <th>2</th>\n",
       "      <th>2.1</th>\n",
       "      <th>small</th>\n",
       "      <th>low</th>\n",
       "      <th>unacc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>small</td>\n",
       "      <td>med</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>small</td>\n",
       "      <td>high</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>med</td>\n",
       "      <td>low</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>med</td>\n",
       "      <td>med</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>med</td>\n",
       "      <td>high</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   vhigh vhigh.1  2 2.1  small   low  unacc\n",
       "0  vhigh   vhigh  2   2  small   med  unacc\n",
       "1  vhigh   vhigh  2   2  small  high  unacc\n",
       "2  vhigh   vhigh  2   2    med   low  unacc\n",
       "3  vhigh   vhigh  2   2    med   med  unacc\n",
       "4  vhigh   vhigh  2   2    med  high  unacc"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Nomeando colunas do dataset\n",
    "dataset.columns = ['buying','maint','doors','persons','lug_boot','safety','classs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>buying</th>\n",
       "      <th>maint</th>\n",
       "      <th>doors</th>\n",
       "      <th>persons</th>\n",
       "      <th>lug_boot</th>\n",
       "      <th>safety</th>\n",
       "      <th>classs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>small</td>\n",
       "      <td>med</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>small</td>\n",
       "      <td>high</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>med</td>\n",
       "      <td>low</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>med</td>\n",
       "      <td>med</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>med</td>\n",
       "      <td>high</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  buying  maint doors persons lug_boot safety classs\n",
       "0  vhigh  vhigh     2       2    small    med  unacc\n",
       "1  vhigh  vhigh     2       2    small   high  unacc\n",
       "2  vhigh  vhigh     2       2      med    low  unacc\n",
       "3  vhigh  vhigh     2       2      med    med  unacc\n",
       "4  vhigh  vhigh     2       2      med   high  unacc"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "med      432\n",
       "high     432\n",
       "low      432\n",
       "vhigh    431\n",
       "Name: buying, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.value_counts(dataset['buying'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dataBuying=pd.value_counts(dataset['buying'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>buying</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>med</th>\n",
       "      <td>432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>high</th>\n",
       "      <td>432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>low</th>\n",
       "      <td>432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vhigh</th>\n",
       "      <td>431</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       buying\n",
       "med       432\n",
       "high      432\n",
       "low       432\n",
       "vhigh     431"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframeBuying=pd.DataFrame(dataBuying)\n",
    "type(dataframeBuying)\n",
    "dataframeBuying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1209"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MANIPULAÇÃO DO DATAFRAME PELA CLASSE\n",
    "# FOI IMPLEMENTADO UMA FUNCAO PARA ESSA PARTE!\n",
    "\n",
    "dataClass=pd.value_counts(dataset['classs'])\n",
    "dataframeClass=pd.DataFrame(dataClass)\n",
    "\n",
    "# Filtragem por CLASSE\n",
    "data_class_unacc = dataset.loc[(dataset['classs']=='unacc')]\n",
    "data_class_acc = dataset.loc[(dataset['classs']=='acc')]\n",
    "data_class_good = dataset.loc[(dataset['classs']=='good')]\n",
    "data_class_vgood = dataset.loc[(dataset['classs']=='vgood')]\n",
    "\n",
    "# Quantidade total de elementos por classe\n",
    "total_el_unacc = data_class_unacc['classs'].count()\n",
    "total_el_acc = data_class_acc['classs'].count()\n",
    "total_el_good = data_class_good['classs'].count()\n",
    "total_el_vgood = data_class_vgood['classs'].count()\n",
    "\n",
    "total_el_unacc\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "431 432 432 432 1727\n"
     ]
    }
   ],
   "source": [
    "# MANIPULAÇAO DO DATAFRAME PELO ATRIBUTO BUYING\n",
    "\n",
    "# O PASSO DE FILTRAGEM A SEGUIR JA CONTEM FUNCAO IMPLEMENTADA\n",
    "# FIltragem dos BUYING = 'vhigh'\n",
    "data_vhigh=dataset.loc[(dataset['buying']=='vhigh')]\n",
    "\n",
    "# Filtragem dos BUYNG='high'\n",
    "data_high=dataset.loc[(dataset['buying']=='high')]\n",
    "\n",
    "# Filtragem dos BUYNG='med'\n",
    "data_med=dataset.loc[(dataset['buying']=='med')]\n",
    "\n",
    "# Filtragem dos BUYNG='low'\n",
    "data_low=dataset.loc[(dataset['buying']=='low')]\n",
    "\n",
    "# Filtragem dos BUYNG='vhigh' && CLASS='unacc'\n",
    "data_vhigh_unacc=dataset.loc[(dataset['buying']=='vhigh') & (dataset['classs']=='unacc')]\n",
    "\n",
    "# Filtragem dos BUYNG='high' && CLASS='unacc'\n",
    "data_high_unacc=dataset.loc[(dataset['buying']=='high') & (dataset['classs']=='unacc')]\n",
    "\n",
    "# Filtragem dos BUYNG='med' && CLASS='unacc'\n",
    "data_med_unacc=dataset.loc[(dataset['buying']=='med') & (dataset['classs']=='unacc')]\n",
    "\n",
    "# Filtragem dos BUYNG='low' && CLASS='unacc'\n",
    "data_low_unacc=dataset.loc[(dataset['buying']=='low') & (dataset['classs']=='unacc')]\n",
    "\n",
    "\n",
    "\n",
    "# Filtragem dos BUYNG='vhigh' && CLASS='acc'\n",
    "data_vhigh_acc=dataset.loc[(dataset['buying']=='vhigh') & (dataset['classs']=='acc')]\n",
    "\n",
    "# Filtragem dos BUYNG='high' && CLASS='acc'\n",
    "data_high_acc=dataset.loc[(dataset['buying']=='high') & (dataset['classs']=='acc')]\n",
    "\n",
    "# Filtragem dos BUYNG='med' && CLASS='acc'\n",
    "data_med_acc=dataset.loc[(dataset['buying']=='med') & (dataset['classs']=='acc')]\n",
    "\n",
    "# Filtragem dos BUYNG='low' && CLASS='acc'\n",
    "data_low_acc=dataset.loc[(dataset['buying']=='low') & (dataset['classs']=='acc')]\n",
    "\n",
    "\n",
    "\n",
    "# Filtragem dos BUYNG='vhigh' && CLASS='good'\n",
    "data_vhigh_good=dataset.loc[(dataset['buying']=='vhigh') & (dataset['classs']=='good')]\n",
    "\n",
    "# Filtragem dos BUYNG='high' && CLASS='good'\n",
    "data_high_good=dataset.loc[(dataset['buying']=='high') & (dataset['classs']=='good')]\n",
    "\n",
    "# Filtragem dos BUYNG='med' && CLASS='good'\n",
    "data_med_good=dataset.loc[(dataset['buying']=='med') & (dataset['classs']=='good')]\n",
    "\n",
    "# Filtragem dos BUYNG='low' && CLASS='good'\n",
    "data_low_good=dataset.loc[(dataset['buying']=='low') & (dataset['classs']=='good')]\n",
    "\n",
    "\n",
    "\n",
    "# Filtragem dos BUYNG='vhigh' && CLASS='vgood'\n",
    "data_vhigh_vgood=dataset.loc[(dataset['buying']=='vhigh') & (dataset['classs']=='vgood')]\n",
    "\n",
    "# Filtragem dos BUYNG='high' && CLASS='vgood'\n",
    "data_high_vgood=dataset.loc[(dataset['buying']=='high') & (dataset['classs']=='vgood')]\n",
    "\n",
    "# Filtragem dos BUYNG='med' && CLASS='vgood'\n",
    "data_med_vgood=dataset.loc[(dataset['buying']=='med') & (dataset['classs']=='vgood')]\n",
    "\n",
    "# Filtragem dos BUYNG='low' && CLASS='vgood'\n",
    "data_low_vgood=dataset.loc[(dataset['buying']=='low') & (dataset['classs']=='vgood')]\n",
    "\n",
    "\n",
    "\n",
    "# CONTAGEM DE ELEMENTOS\n",
    "# IMPLEMENTAÇÃO DA FUNCAO FINALIZADA\n",
    "\n",
    "# Quantidade total de elementos\n",
    "total_elementos = dataset['buying'].count()\n",
    "\n",
    "# Total vhigh\n",
    "total_vhigh = data_vhigh['buying'].count()\n",
    "\n",
    "# Total high\n",
    "total_high = data_high['buying'].count()\n",
    "\n",
    "# Total med\n",
    "total_med = data_med['buying'].count()\n",
    "\n",
    "# Total low \n",
    "total_low = data_low['buying'].count()\n",
    "\n",
    "# IMPLEMENTANDO\n",
    "# TABELA DE FREQUENCIA PARA BUYING/CLASS\n",
    "# Total vhigh p/ classe unacc\n",
    "total_vhigh_unacc = data_vhigh_unacc['buying'].count()\n",
    "\n",
    "# Total high p/ classe unacc\n",
    "total_high_unacc = data_high_unacc['buying'].count()\n",
    "\n",
    "# Total med p/ classe unacc\n",
    "total_med_unacc = data_med_unacc['buying'].count()\n",
    "\n",
    "# Total low p/ classe unacc\n",
    "total_low_unacc = data_low_unacc['buying'].count()\n",
    "\n",
    "\n",
    "# Total vhigh p/ classe acc\n",
    "total_vhigh_acc = data_vhigh_acc['buying'].count()\n",
    "\n",
    "# Total high p/ classe acc\n",
    "total_high_acc = data_high_acc['buying'].count()\n",
    "\n",
    "# Total med p/ classe acc\n",
    "total_med_acc = data_med_acc['buying'].count()\n",
    "\n",
    "# Total low p/ classe acc\n",
    "total_low_acc = data_low_acc['buying'].count()\n",
    "\n",
    "\n",
    "# Total vhigh p/ classe good\n",
    "total_vhigh_good = data_vhigh_good['buying'].count()\n",
    "\n",
    "# Total high p/ classe good\n",
    "total_high_good = data_high_good['buying'].count()\n",
    "\n",
    "# Total med p/ classe unacc\n",
    "total_med_good = data_med_good['buying'].count()\n",
    "\n",
    "# Total low p/ classe unacc\n",
    "total_low_good = data_low_good['buying'].count()\n",
    "\n",
    "\n",
    "# Total vhigh p/ classe vgood\n",
    "total_vhigh_vgood = data_vhigh_good['buying'].count()\n",
    "\n",
    "# Total high p/ classe vgood\n",
    "total_high_vgood = data_high_vgood['buying'].count()\n",
    "\n",
    "# Total med p/ classe unacc\n",
    "total_med_vgood = data_med_vgood['buying'].count()\n",
    "\n",
    "# Total low p/ classe unacc\n",
    "total_low_vgood = data_low_vgood['buying'].count()\n",
    "\n",
    "\n",
    "print(total_vhigh,total_high,total_med,total_low,total_elementos)\n",
    "# total_elementos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p_unacc_vhigh : 0.8329466357308586\n",
      "p_acc_vhigh : 0.16705336426914155\n",
      "p_good_vhigh : 0.0\n",
      "p_vgood_vhigh : 0.0\n"
     ]
    }
   ],
   "source": [
    "# NAIVE BAYES\n",
    "# FALTA IMPLEMENTAR FUNCOES QUE FAZEM ESSE BLOCO!\n",
    "\n",
    "# P(class|atrib) = [P(atri|class)*P(class)]/P(atrib)\n",
    "\n",
    "# P(atributo|uncc)\n",
    "p_vhigh_unacc = total_vhigh_unacc/total_el_unacc\n",
    "p_high_unacc = total_high_unacc/total_el_unacc\n",
    "p_med_unacc = total_med_unacc/total_el_unacc\n",
    "p_low_unacc = total_low_unacc/total_el_unacc\n",
    "\n",
    "# P(atributo|acc)\n",
    "p_vhigh_acc = total_vhigh_acc/total_el_acc\n",
    "p_high_acc = total_high_acc/total_el_acc\n",
    "p_med_acc = total_med_acc/total_el_acc\n",
    "p_low_acc = total_low_acc/total_el_acc\n",
    "\n",
    "# P(atributo|good)\n",
    "p_vhigh_good = total_vhigh_good/total_el_good\n",
    "p_high_good = total_high_good/total_el_good\n",
    "p_med_good = total_med_good/total_el_good\n",
    "p_low_good = total_low_good/total_el_good\n",
    "\n",
    "# P(atributo|vgood)\n",
    "p_vhigh_vgood = total_vhigh_vgood/total_el_vgood\n",
    "p_high_vgood = total_high_vgood/total_el_vgood\n",
    "p_med_vgood = total_med_vgood/total_el_vgood\n",
    "p_low_vgood = total_low_vgood/total_el_vgood\n",
    "\n",
    "# P(vhigh)\n",
    "p_vhigh = total_vhigh/total_elementos\n",
    "\n",
    "# P(high)\n",
    "p_high = total_high/total_elementos\n",
    "\n",
    "# P(med)\n",
    "p_med = total_med/total_elementos\n",
    "\n",
    "# P(low)\n",
    "p_low = total_low/total_elementos\n",
    "\n",
    "# P(class)\n",
    "p_unacc = total_el_unacc/total_elementos\n",
    "p_acc = total_el_acc/total_elementos\n",
    "p_good = total_el_good/total_elementos\n",
    "p_vgood = total_el_vgood/total_elementos\n",
    "\n",
    "# P(uncc|vhigh) = \n",
    "p_unacc_vhigh = (p_vhigh_unacc * p_unacc)/(p_vhigh)\n",
    "\n",
    "# P(acc|vhigh)\n",
    "p_acc_vhigh = (p_vhigh_acc * p_acc)/(p_vhigh)\n",
    "\n",
    "# P(good|vhigh)\n",
    "p_good_vhigh = (p_vhigh_good * p_good)/(p_vhigh)\n",
    "\n",
    "# P(vgood|vhigh)\n",
    "p_vgood_vhigh = (p_vhigh_vgood * p_vgood)/(p_vhigh)\n",
    "\n",
    "#v_p_vhigh[]=p_unacc_vhigh,p_acc_vhigh,p_good_vhigh,p_vgood_vhigh\n",
    "#prob_test = max(v_p_vhigh)\n",
    "\n",
    "print((\"p_unacc_vhigh : {0}\\np_acc_vhigh : {1}\\np_good_vhigh : {2}\\np_vgood_vhigh : {3}\").format(p_unacc_vhigh,p_acc_vhigh,p_good_vhigh,p_vgood_vhigh))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['unacc', 'acc', 'vgood', 'good'], dtype=object)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LISTA ELEMENTOS UNICOS DE UMA COLUNA\n",
    "teste=dataset.classs.unique()\n",
    "teste\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 359, 1: 72, 2: 0, 3: 0, 4: 324, 5: 108, 6: 0, 7: 0, 8: 268, 9: 115, 10: 26, 11: 23, 12: 258, 13: 89, 14: 39, 15: 46, 16: 359, 17: 72, 18: 0, 19: 0, 20: 314, 21: 105, 22: 13, 23: 0, 24: 268, 25: 115, 26: 26, 27: 23, 28: 268, 29: 92, 30: 26, 31: 46, 32: 325, 33: 81, 34: 10, 35: 15, 36: 300, 37: 99, 38: 15, 39: 18, 40: 292, 41: 102, 42: 20, 43: 18, 44: 292, 45: 102, 46: 20, 47: 18, 48: 575, 49: 0, 50: 0, 51: 0, 52: 312, 53: 198, 54: 30, 55: 36, 56: 322, 57: 186, 58: 35, 59: 33, 60: 449, 61: 105, 62: 0, 63: 21, 64: 392, 65: 135, 66: 25, 67: 24, 68: 368, 69: 144, 70: 40, 71: 24, 72: 357, 73: 180, 74: 0, 75: 39, 76: 277, 77: 204, 78: 65, 79: 30, 80: 575, 81: 0, 82: 0, 83: 0}\n"
     ]
    }
   ],
   "source": [
    "# ALGUMAS FUNCOES JA PRONTAS! FALTA FAZER O PASSO DA CONTAGEM AGORA.\n",
    "\n",
    "\n",
    "# # MANIPULAÇÃO DO DATAFRAME PELA CLASSE\n",
    "\n",
    "# dataClass=pd.value_counts(dataset['classs'])\n",
    "# dataframeClass=pd.DataFrame(dataClass)\n",
    "\n",
    "# Funcao abaixo esta funcionando!\n",
    "# A classe retorna um dicionario de DATAFRAMES e Total elementos de cada Dataframe\n",
    "# Para acessar primeiro dataframe: separatedByClass[0]\n",
    "# def separatedByClass(dataset):\n",
    "#     class_element_v = dataset.classs.unique()\n",
    "#     separatedByClass = {}\n",
    "#     total_el_class = {}\n",
    "#     for i in range(0,4):\n",
    "#         separatedByClass[i] = dataset.loc[(dataset['classs']==class_element_v[i])]\n",
    "#         total_el_class[i] = separatedByClass[i]['classs'].count()\n",
    "#     return separetedByClass, total_el_class\n",
    "\n",
    "\n",
    "\n",
    "# MANIPULAÇAO DO DATAFRAME PELO ATRIBUTO BUYING\n",
    "\n",
    "# A funcao a seguir retorna a filtragem por atributos de cada coluna\n",
    "# Retorna um dicionario com 21 elementos (0 a 20)\n",
    "# def separatedByFeature(dataset):\n",
    "#     data_columns = dataset.columns\n",
    "#     len_columns = len(data_columns)-1\n",
    "#     separatedByFeature = {}\n",
    "#     total_el_features = {}\n",
    "#     k=0\n",
    "#     for i in range(0,len_columns):\n",
    "#         feature = dataset[data_columns[i]].unique() # Elementos de cada Feature\n",
    "#         len_feature = len(feature)\n",
    "#         for j in range(0,len_feature):\n",
    "#             data_filter_feature = dataset.loc[(dataset[data_columns[i]] == feature[j])] \n",
    "#             separatedByFeature[k] = data_filter_feature\n",
    "#             total_el_features[k] = separatedByFeature[k][data_columns[i]].count()\n",
    "#             k=k+1\n",
    "#     return separatedByFeature, total_el_features\n",
    "\n",
    "############################################## INICIO TESTAR FUNCOES #####################################################\n",
    "\n",
    "class_element_v = dataset.classs.unique()\n",
    "separatedByClass = {}\n",
    "total_el_class = {}\n",
    "for i in range(0,4):\n",
    "    separatedByClass[i] = dataset.loc[(dataset['classs']==class_element_v[i])]\n",
    "    total_el_class[i] = separatedByClass[i]['classs'].count()\n",
    "\n",
    "data_columns = dataset.columns\n",
    "len_columns = len(data_columns)-1\n",
    "separatedByFeature = {}\n",
    "total_el_features = {}\n",
    "k=0\n",
    "for i in range(0,len_columns):\n",
    "    feature = dataset[data_columns[i]].unique() # Elementos de cada Feature\n",
    "    len_feature = len(feature)\n",
    "    for j in range(0,len_feature):\n",
    "        data_filter_feature = dataset.loc[(dataset[data_columns[i]] == feature[j])] \n",
    "        separatedByFeature[k] = data_filter_feature\n",
    "        total_el_features[k] = separatedByFeature[k][data_columns[i]].count()\n",
    "        k=k+1\n",
    "\n",
    "len_dic = len(separatedByFeature)\n",
    "# data_columns = dataset.columns\n",
    "# len_columns = len(data_columns)-1\n",
    "separatedByFeatureClass = {}\n",
    "total_el_feature_class = {}\n",
    "k = 0\n",
    "for i in range (0,len_dic):\n",
    "    if (i>=0 and i<16):\n",
    "        data_filter_feature_class = separatedByFeature[i].loc[(separatedByFeature[i]['classs']==class_element_v[0])]\n",
    "        separatedByFeatureClass[k] = data_filter_feature_class\n",
    "        total_el_feature_class[k] = separatedByFeatureClass[k]['buying'].count()\n",
    "        k=k+1\n",
    "        data_filter_feature_class = separatedByFeature[i].loc[(separatedByFeature[i]['classs']==class_element_v[1])]\n",
    "        separatedByFeatureClass[k] = data_filter_feature_class\n",
    "        total_el_feature_class[k] = separatedByFeatureClass[k]['buying'].count()\n",
    "        k=k+1\n",
    "        data_filter_feature_class = separatedByFeature[i].loc[(separatedByFeature[i]['classs']==class_element_v[2])]\n",
    "        separatedByFeatureClass[k] = data_filter_feature_class\n",
    "        total_el_feature_class[k] = separatedByFeatureClass[k]['buying'].count()\n",
    "        k=k+1\n",
    "        data_filter_feature_class = separatedByFeature[i].loc[(separatedByFeature[i]['classs']==class_element_v[3])]\n",
    "        separatedByFeatureClass[k] = data_filter_feature_class\n",
    "        total_el_feature_class[k] = separatedByFeatureClass[k]['buying'].count()\n",
    "        k=k+1\n",
    "    elif (i>=16 and i<32):\n",
    "        data_filter_feature_class = separatedByFeature[i].loc[(separatedByFeature[i]['classs']==class_element_v[0])]\n",
    "        separatedByFeatureClass[k] = data_filter_feature_class\n",
    "        total_el_feature_class[k] = separatedByFeatureClass[k]['maint'].count()\n",
    "        k=k+1\n",
    "        data_filter_feature_class = separatedByFeature[i].loc[(separatedByFeature[i]['classs']==class_element_v[1])]\n",
    "        separatedByFeatureClass[k] = data_filter_feature_class\n",
    "        total_el_feature_class[k] = separatedByFeatureClass[k]['maint'].count()\n",
    "        k=k+1\n",
    "        data_filter_feature_class = separatedByFeature[i].loc[(separatedByFeature[i]['classs']==class_element_v[2])]\n",
    "        separatedByFeatureClass[k] = data_filter_feature_class\n",
    "        total_el_feature_class[k] = separatedByFeatureClass[k]['maint'].count()\n",
    "        k=k+1\n",
    "        data_filter_feature_class = separatedByFeature[i].loc[(separatedByFeature[i]['classs']==class_element_v[3])]\n",
    "        separatedByFeatureClass[k] = data_filter_feature_class\n",
    "        total_el_feature_class[k] = separatedByFeatureClass[k]['maint'].count()\n",
    "        k=k+1\n",
    "    elif (i>=32 and i<48):\n",
    "        data_filter_feature_class = separatedByFeature[i].loc[(separatedByFeature[i]['classs']==class_element_v[0])]\n",
    "        separatedByFeatureClass[k] = data_filter_feature_class\n",
    "        total_el_feature_class[k] = separatedByFeatureClass[k]['doors'].count()\n",
    "        k=k+1\n",
    "        data_filter_feature_class = separatedByFeature[i].loc[(separatedByFeature[i]['classs']==class_element_v[1])]\n",
    "        separatedByFeatureClass[k] = data_filter_feature_class\n",
    "        total_el_feature_class[k] = separatedByFeatureClass[k]['doors'].count()\n",
    "        k=k+1\n",
    "        data_filter_feature_class = separatedByFeature[i].loc[(separatedByFeature[i]['classs']==class_element_v[2])]\n",
    "        separatedByFeatureClass[k] = data_filter_feature_class\n",
    "        total_el_feature_class[k] = separatedByFeatureClass[k]['doors'].count()\n",
    "        k=k+1\n",
    "        data_filter_feature_class = separatedByFeature[i].loc[(separatedByFeature[i]['classs']==class_element_v[3])]\n",
    "        separatedByFeatureClass[k] = data_filter_feature_class\n",
    "        total_el_feature_class[k] = separatedByFeatureClass[k]['doors'].count()\n",
    "        k=k+1\n",
    "    elif (i>=48 and i<60):\n",
    "        data_filter_feature_class = separatedByFeature[i].loc[(separatedByFeature[i]['classs']==class_element_v[0])]\n",
    "        separatedByFeatureClass[k] = data_filter_feature_class\n",
    "        total_el_feature_class[k] = separatedByFeatureClass[k]['persons'].count()\n",
    "        k=k+1\n",
    "        data_filter_feature_class = separatedByFeature[i].loc[(separatedByFeature[i]['classs']==class_element_v[1])]\n",
    "        separatedByFeatureClass[k] = data_filter_feature_class\n",
    "        total_el_feature_class[k] = separatedByFeatureClass[k]['persons'].count()\n",
    "        k=k+1\n",
    "        data_filter_feature_class = separatedByFeature[i].loc[(separatedByFeature[i]['classs']==class_element_v[2])]\n",
    "        separatedByFeatureClass[k] = data_filter_feature_class\n",
    "        total_el_feature_class[k] = separatedByFeatureClass[k]['persons'].count()\n",
    "        k=k+1\n",
    "        data_filter_feature_class = separatedByFeature[i].loc[(separatedByFeature[i]['classs']==class_element_v[3])]\n",
    "        separatedByFeatureClass[k] = data_filter_feature_class\n",
    "        total_el_feature_class[k] = separatedByFeatureClass[k]['persons'].count()\n",
    "        k=k+1\n",
    "    elif (i>=60 and i<72):\n",
    "        data_filter_feature_class = separatedByFeature[i].loc[(separatedByFeature[i]['classs']==class_element_v[0])]\n",
    "        separatedByFeatureClass[k] = data_filter_feature_class\n",
    "        total_el_feature_class[k] = separatedByFeatureClass[k]['lug_boot'].count()\n",
    "        k=k+1\n",
    "        data_filter_feature_class = separatedByFeature[i].loc[(separatedByFeature[i]['classs']==class_element_v[1])]\n",
    "        separatedByFeatureClass[k] = data_filter_feature_class\n",
    "        total_el_feature_class[k] = separatedByFeatureClass[k]['lug_boot'].count()\n",
    "        k=k+1\n",
    "        data_filter_feature_class = separatedByFeature[i].loc[(separatedByFeature[i]['classs']==class_element_v[2])]\n",
    "        separatedByFeatureClass[k] = data_filter_feature_class\n",
    "        total_el_feature_class[k] = separatedByFeatureClass[k]['lug_boot'].count()\n",
    "        k=k+1\n",
    "        data_filter_feature_class = separatedByFeature[i].loc[(separatedByFeature[i]['classs']==class_element_v[3])]\n",
    "        separatedByFeatureClass[k] = data_filter_feature_class\n",
    "        total_el_feature_class[k] = separatedByFeatureClass[k]['lug_boot'].count()\n",
    "        k=k+1\n",
    "    elif (i>=72 and i<len_dic):\n",
    "        data_filter_feature_class = separatedByFeature[i].loc[(separatedByFeature[i]['classs']==class_element_v[0])]\n",
    "        separatedByFeatureClass[k] = data_filter_feature_class\n",
    "        total_el_feature_class[k] = separatedByFeatureClass[k]['lug_boot'].count()\n",
    "        k=k+1\n",
    "        data_filter_feature_class = separatedByFeature[i].loc[(separatedByFeature[i]['classs']==class_element_v[1])]\n",
    "        separatedByFeatureClass[k] = data_filter_feature_class\n",
    "        total_el_feature_class[k] = separatedByFeatureClass[k]['lug_boot'].count()\n",
    "        k=k+1\n",
    "        data_filter_feature_class = separatedByFeature[i].loc[(separatedByFeature[i]['classs']==class_element_v[2])]\n",
    "        separatedByFeatureClass[k] = data_filter_feature_class\n",
    "        total_el_feature_class[k] = separatedByFeatureClass[k]['lug_boot'].count()\n",
    "        k=k+1\n",
    "        data_filter_feature_class = separatedByFeature[i].loc[(separatedByFeature[i]['classs']==class_element_v[3])]\n",
    "        separatedByFeatureClass[k] = data_filter_feature_class\n",
    "        total_el_feature_class[k] = separatedByFeatureClass[k]['lug_boot'].count()\n",
    "        k=k+1\n",
    "print(total_el_feature_class)\n",
    "\n",
    "############################################## FINAL TESTAR FUNCOES #####################################################\n",
    "\n",
    "# A FUNCAO ABAIXO RETORNA UM DIC DE 84 ITENS\n",
    "# É REALIZADO UMA FILTRAGEM DE CADA FEATURE & CADA CLASS. LOGO, SAO 4 DATAFRAMES PARA CADA ELEMENTO DE FEATURE 21*4\n",
    "# EXEMPLO: data_vhigh_unacc=dataset.loc[(dataset['buying']=='vhigh') & (dataset['classs']=='unacc')]\n",
    "# def separatedByFeatureClass(dic)\n",
    "#     class_element_v = dic[0].classs.unique()\n",
    "#     len_dic = len(dic)\n",
    "#     separatedByFeatureClass = {}\n",
    "#     total_el_feature_class = {}\n",
    "#     k = 0\n",
    "#     for i in range (0,len_dic):\n",
    "#         if (i>=0 and i<16):\n",
    "#             data_filter_feature_class = dic[i].loc[(dic[i]['classs']==class_element_v[0])]\n",
    "#             separatedByFeatureClass[k] = data_filter_feature_class\n",
    "#             total_el_feature_class[k] = separatedByFeatureClass[k]['buying'].count()\n",
    "#             k=k+1\n",
    "#             data_filter_feature_class = dic[i].loc[(dic[i]['classs']==class_element_v[1])]\n",
    "#             separatedByFeatureClass[k] = data_filter_feature_class\n",
    "#             total_el_feature_class[k] = separatedByFeatureClass[k]['buying'].count()\n",
    "#             k=k+1\n",
    "#             data_filter_feature_class = dic[i].loc[(dic[i]['classs']==class_element_v[2])]\n",
    "#             separatedByFeatureClass[k] = data_filter_feature_class\n",
    "#             total_el_feature_class[k] = separatedByFeatureClass[k]['buying'].count()\n",
    "#             k=k+1\n",
    "#             data_filter_feature_class = dic[i].loc[(dic[i]['classs']==class_element_v[3])]\n",
    "#             separatedByFeatureClass[k] = data_filter_feature_class\n",
    "#             total_el_feature_class[k] = separatedByFeatureClass[k]['buying'].count()\n",
    "#             k=k+1\n",
    "#         elif (i>=16 and i<32):\n",
    "#             data_filter_feature_class = dic[i].loc[(dic[i]['classs']==class_element_v[0])]\n",
    "#             separatedByFeatureClass[k] = data_filter_feature_class\n",
    "#             total_el_feature_class[k] = separatedByFeatureClass[k]['maint'].count()\n",
    "#             k=k+1\n",
    "#             data_filter_feature_class = dic[i].loc[(dic[i]['classs']==class_element_v[1])]\n",
    "#             separatedByFeatureClass[k] = data_filter_feature_class\n",
    "#             total_el_feature_class[k] = separatedByFeatureClass[k]['maint'].count()\n",
    "#             k=k+1\n",
    "#             data_filter_feature_class = dic[i].loc[(dic[i]['classs']==class_element_v[2])]\n",
    "#             separatedByFeatureClass[k] = data_filter_feature_class\n",
    "#             total_el_feature_class[k] = separatedByFeatureClass[k]['maint'].count()\n",
    "#             k=k+1\n",
    "#             data_filter_feature_class = dic[i].loc[(dic[i]['classs']==class_element_v[3])]\n",
    "#             separatedByFeatureClass[k] = data_filter_feature_class\n",
    "#             total_el_feature_class[k] = separatedByFeatureClass[k]['maint'].count()\n",
    "#             k=k+1\n",
    "#         elif (i>=32 and i<48):\n",
    "#             data_filter_feature_class = dic[i].loc[(dic[i]['classs']==class_element_v[0])]\n",
    "#             separatedByFeatureClass[k] = data_filter_feature_class\n",
    "#             total_el_feature_class[k] = separatedByFeatureClass[k]['doors'].count()\n",
    "#             k=k+1\n",
    "#             data_filter_feature_class = dic[i].loc[(dic[i]['classs']==class_element_v[1])]\n",
    "#             separatedByFeatureClass[k] = data_filter_feature_class\n",
    "#             total_el_feature_class[k] = separatedByFeatureClass[k]['doors'].count()\n",
    "#             k=k+1\n",
    "#             data_filter_feature_class = dic[i].loc[(dic[i]['classs']==class_element_v[2])]\n",
    "#             separatedByFeatureClass[k] = data_filter_feature_class\n",
    "#             total_el_feature_class[k] = separatedByFeatureClass[k]['doors'].count()\n",
    "#             k=k+1\n",
    "#             data_filter_feature_class = dic[i].loc[(dic[i]['classs']==class_element_v[3])]\n",
    "#             separatedByFeatureClass[k] = data_filter_feature_class\n",
    "#             total_el_feature_class[k] = separatedByFeatureClass[k]['doors'].count()\n",
    "#             k=k+1\n",
    "#         elif (i>=48 and i<60):\n",
    "#             data_filter_feature_class = dic[i].loc[(dic[i]['classs']==class_element_v[0])]\n",
    "#             separatedByFeatureClass[k] = data_filter_feature_class\n",
    "#             total_el_feature_class[k] = separatedByFeatureClass[k]['persons'].count()\n",
    "#             k=k+1\n",
    "#             data_filter_feature_class = dic[i].loc[(dic[i]['classs']==class_element_v[1])]\n",
    "#             separatedByFeatureClass[k] = data_filter_feature_class\n",
    "#             total_el_feature_class[k] = separatedByFeatureClass[k]['persons'].count()\n",
    "#             k=k+1\n",
    "#             data_filter_feature_class = dic[i].loc[(dic[i]['classs']==class_element_v[2])]\n",
    "#             separatedByFeatureClass[k] = data_filter_feature_class\n",
    "#             total_el_feature_class[k] = separatedByFeatureClass[k]['persons'].count()\n",
    "#             k=k+1\n",
    "#             data_filter_feature_class = dic[i].loc[(dic[i]['classs']==class_element_v[3])]\n",
    "#             separatedByFeatureClass[k] = data_filter_feature_class\n",
    "#             total_el_feature_class[k] = separatedByFeatureClass[k]['persons'].count()\n",
    "#             k=k+1\n",
    "#         elif (i>=60 and i<72):\n",
    "#             data_filter_feature_class = dic[i].loc[(dic[i]['classs']==class_element_v[0])]\n",
    "#             separatedByFeatureClass[k] = data_filter_feature_class\n",
    "#             total_el_feature_class[k] = separatedByFeatureClass[k]['lug_boot'].count()\n",
    "#             k=k+1\n",
    "#             data_filter_feature_class = dic[i].loc[(dic[i]['classs']==class_element_v[1])]\n",
    "#             separatedByFeatureClass[k] = data_filter_feature_class\n",
    "#             total_el_feature_class[k] = separatedByFeatureClass[k]['lug_boot'].count()\n",
    "#             k=k+1\n",
    "#             data_filter_feature_class = dic[i].loc[(dic[i]['classs']==class_element_v[2])]\n",
    "#             separatedByFeatureClass[k] = data_filter_feature_class\n",
    "#             total_el_feature_class[k] = separatedByFeatureClass[k]['lug_boot'].count()\n",
    "#             k=k+1\n",
    "#             data_filter_feature_class = dic[i].loc[(dic[i]['classs']==class_element_v[3])]\n",
    "#             separatedByFeatureClass[k] = data_filter_feature_class\n",
    "#             total_el_feature_class[k] = separatedByFeatureClass[k]['lug_boot'].count()\n",
    "#             k=k+1\n",
    "#         elif (i>=72 and i<len_dic):\n",
    "#             data_filter_feature_class = dic[i].loc[(dic[i]['classs']==class_element_v[0])]\n",
    "#             separatedByFeatureClass[k] = data_filter_feature_class\n",
    "#             total_el_feature_class[k] = separatedByFeatureClass[k]['lug_boot'].count()\n",
    "#             k=k+1\n",
    "#             data_filter_feature_class = dic[i].loc[(dic[i]['classs']==class_element_v[1])]\n",
    "#             separatedByFeatureClass[k] = data_filter_feature_class\n",
    "#             total_el_feature_class[k] = separatedByFeatureClass[k]['lug_boot'].count()\n",
    "#             k=k+1\n",
    "#             data_filter_feature_class = dic[i].loc[(dic[i]['classs']==class_element_v[2])]\n",
    "#             separatedByFeatureClass[k] = data_filter_feature_class\n",
    "#             total_el_feature_class[k] = separatedByFeatureClass[k]['lug_boot'].count()\n",
    "#             k=k+1\n",
    "#             data_filter_feature_class = dic[i].loc[(dic[i]['classs']==class_element_v[3])]\n",
    "#             separatedByFeatureClass[k] = data_filter_feature_class\n",
    "#             total_el_feature_class[k] = separatedByFeatureClass[k]['lug_boot'].count()\n",
    "#             k=k+1\n",
    "#     return separatedByFeatureClass, total_el_feature_class\n",
    "\n",
    "\n",
    "# def main():\n",
    "#     filename=dataset\n",
    "#     nhae = separateByClass(filename)\n",
    "#     print(nhae)\n",
    "# if __name__ == \"__main__\":\n",
    "#     main()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'buying'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nhae=dataset.columns\n",
    "type(nhae)\n",
    "nhae[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# IMPLEMENTACAO DO NAIVE BAYES FEITA PELO PROF PARA NUMEROS\n",
    "\n",
    "\n",
    "import csv\n",
    "import math\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    " \n",
    "def loadCsv(filename):\n",
    "    lines = csv.reader(open(filename, \"r\"))\n",
    "    dataset = list(lines)\n",
    "    for i in range(len(dataset)):\n",
    "        dataset[i] = [str(x) for x in dataset[i]]\n",
    "    return dataset    \n",
    "\n",
    "def splitDataset(dataset, splitRatio):\n",
    "    trainSize = int(len(dataset) * splitRatio)\n",
    "    trainSet = []\n",
    "    copy = list(dataset)\n",
    "    \n",
    "    while len(trainSet) < trainSize:\n",
    "        index = random.randrange(len(copy))\n",
    "        trainSet.append(copy.pop(index))\n",
    "    return [trainSet, copy]\n",
    "\n",
    "def separateByClass(dataset):\n",
    "    separated = {}\n",
    "    for i in range(len(dataset)):\n",
    "        vector = dataset[i]\n",
    "        if (vector[-1] not in separated):\n",
    "            separated[vector[-1]] = []\n",
    "        separated[vector[-1]].append(vector)\n",
    "    return separated\n",
    "\n",
    "\n",
    "\n",
    "#### fazer a tabela de probabilidade ######\n",
    "#### FAzer uma contagem ###################\n",
    "\n",
    "\n",
    "def mean(numbers):\n",
    "    return sum(numbers)/float(len(numbers))\n",
    " \n",
    "def stdev(numbers):\n",
    "    avg = mean(numbers)\n",
    "    variance = sum([pow(x-avg,2) for x in numbers])/float(len(numbers)-1)\n",
    "    return math.sqrt(variance)\n",
    "\n",
    "def summarize(dataset):\n",
    "    summaries = [(mean(attribute), stdev(attribute)) for attribute in zip(*dataset)]\n",
    "    del summaries[-1]\n",
    "    #for attribute in zip(*dataset):\n",
    "    #    print(attribute)\n",
    "    return summaries\n",
    "\n",
    "def summarizeByClass(dataset):\n",
    "    separated = separateByClass(dataset)\n",
    "    summaries = {}\n",
    "    for classValue, instances in separated.items():\n",
    "        summaries[classValue] = summarize(instances)\n",
    "    return summaries\n",
    "\n",
    "def calculateProbability(x, mean, stdev):\n",
    "    if(stdev==0):\n",
    "        return 0\n",
    "    exponent = math.exp(-(math.pow(x-mean,2)/(2*math.pow(stdev,2))))\n",
    "    return (1 / (math.sqrt(2*math.pi * math.pow(stdev,2))) * exponent)\n",
    "\n",
    "def calculateClassProbabilities(summaries, inputVector):\n",
    "    probabilities = {}\n",
    "    for classValue, classSummaries in summaries.items():\n",
    "        probabilities[classValue] = 1\n",
    "        for i in range(len(classSummaries)):\n",
    "            mean, stdev = classSummaries[i]\n",
    "            x = inputVector[i]\n",
    "            probabilities[classValue] *= calculateProbability(x, mean, stdev)\n",
    "    return probabilities\n",
    "\n",
    "def predict(summaries, inputVector):\n",
    "    probabilities = calculateClassProbabilities(summaries, inputVector)\n",
    "    bestLabel, bestProb = None, -1\n",
    "    for classValue, probability in probabilities.items():\n",
    "        if bestLabel is None or probability > bestProb:\n",
    "            bestProb = probability\n",
    "            bestLabel = classValue\n",
    "    return bestLabel\n",
    "\n",
    "def getPredictions(summaries, testSet):\n",
    "    predictions = []\n",
    "    for i in range(len(testSet)):\n",
    "        result = predict(summaries, testSet[i])\n",
    "        predictions.append(result)\n",
    "    return predictions\n",
    "\n",
    "def getAccuracy(testSet, predictions):\n",
    "    correct = 0\n",
    "    for i in range(len(testSet)):\n",
    "        if testSet[i][-1] == predictions[i]:\n",
    "            correct += 1\n",
    "    return (correct/float(len(testSet))) * 100.0\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
