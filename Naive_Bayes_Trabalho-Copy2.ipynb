{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes - Trabalho\n",
    "\n",
    "## Questão 1\n",
    "\n",
    "Implemente um classifacor Naive Bayes para o problema de predizer a qualidade de um carro. Para este fim, utilizaremos um conjunto de dados referente a qualidade de carros, disponível no [UCI](https://archive.ics.uci.edu/ml/datasets/car+evaluation). Este dataset de carros possui as seguintes features e classe:\n",
    "\n",
    "** Attributos **\n",
    "1. buying: vhigh, high, med, low\n",
    "2. maint: vhigh, high, med, low\n",
    "3. doors: 2, 3, 4, 5, more\n",
    "4. persons: 2, 4, more\n",
    "5. lug_boot: small, med, big\n",
    "6. safety: low, med, high\n",
    "\n",
    "([1, 1, 2, 5, 3, 1, 1])\n",
    "\n",
    "** Classes **\n",
    "1. unacc, acc, good, vgood\n",
    "\n",
    "## Questão 2\n",
    "Crie uma versão de sua implementação usando as funções disponíveis na biblioteca SciKitLearn para o Naive Bayes ([veja aqui](http://scikit-learn.org/stable/modules/naive_bayes.html)) \n",
    "\n",
    "## Questão 3\n",
    "\n",
    "Analise a acurácia dos dois algoritmos e discuta a sua solução."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "###QUESTAO 1#########\n",
    "################ RESOLUCAO ######################################\n",
    "#\n",
    "#    buying: vhigh, high, med, low\n",
    "#    maint: vhigh, high, med, low\n",
    "#    doors: 2, 3, 4, 5, more\n",
    "#    persons: 2, 4, more\n",
    "#    lug_boot: small, med, big\n",
    "#    safety: low, med, high\n",
    "#\n",
    "#   CAR                      car acceptability\n",
    "#   . PRICE                  overall price\n",
    "#   . . buying               buying price\n",
    "#   . . maint                price of the maintenance\n",
    "#   . TECH                   technical characteristics\n",
    "#   . . COMFORT              comfort\n",
    "#   . . . doors              number of doors\n",
    "#   . . . persons            capacity in terms of persons to carry\n",
    "#   . . . lug_boot           the size of luggage boot\n",
    "#   . . safety               estimated safety of the car\n",
    "#\n",
    "\n",
    "import pandas as pd\n",
    "filename='car.data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vhigh</th>\n",
       "      <th>vhigh.1</th>\n",
       "      <th>2</th>\n",
       "      <th>2.1</th>\n",
       "      <th>small</th>\n",
       "      <th>low</th>\n",
       "      <th>unacc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>small</td>\n",
       "      <td>med</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>small</td>\n",
       "      <td>high</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>med</td>\n",
       "      <td>low</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>med</td>\n",
       "      <td>med</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>med</td>\n",
       "      <td>high</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   vhigh vhigh.1  2 2.1  small   low  unacc\n",
       "0  vhigh   vhigh  2   2  small   med  unacc\n",
       "1  vhigh   vhigh  2   2  small  high  unacc\n",
       "2  vhigh   vhigh  2   2    med   low  unacc\n",
       "3  vhigh   vhigh  2   2    med   med  unacc\n",
       "4  vhigh   vhigh  2   2    med  high  unacc"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Nomeando colunas do dataset\n",
    "dataset.columns = ['buying','maint','doors','persons','lug_boot','safety','classs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>buying</th>\n",
       "      <th>maint</th>\n",
       "      <th>doors</th>\n",
       "      <th>persons</th>\n",
       "      <th>lug_boot</th>\n",
       "      <th>safety</th>\n",
       "      <th>classs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>small</td>\n",
       "      <td>med</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>small</td>\n",
       "      <td>high</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>med</td>\n",
       "      <td>low</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>med</td>\n",
       "      <td>med</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>med</td>\n",
       "      <td>high</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  buying  maint doors persons lug_boot safety classs\n",
       "0  vhigh  vhigh     2       2    small    med  unacc\n",
       "1  vhigh  vhigh     2       2    small   high  unacc\n",
       "2  vhigh  vhigh     2       2      med    low  unacc\n",
       "3  vhigh  vhigh     2       2      med    med  unacc\n",
       "4  vhigh  vhigh     2       2      med   high  unacc"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "med      432\n",
       "high     432\n",
       "low      432\n",
       "vhigh    431\n",
       "Name: buying, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.value_counts(dataset['buying'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dataBuying=pd.value_counts(dataset['buying'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>buying</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>med</th>\n",
       "      <td>432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>high</th>\n",
       "      <td>432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>low</th>\n",
       "      <td>432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vhigh</th>\n",
       "      <td>431</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       buying\n",
       "med       432\n",
       "high      432\n",
       "low       432\n",
       "vhigh     431"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframeBuying=pd.DataFrame(dataBuying)\n",
    "type(dataframeBuying)\n",
    "dataframeBuying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1209, 384, 69, 65)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MANIPULAÇÃO DO DATAFRAME PELA CLASSE\n",
    "# FOI IMPLEMENTADO UMA FUNCAO PARA ESSA PARTE!\n",
    "\n",
    "dataClass=pd.value_counts(dataset['classs'])\n",
    "dataframeClass=pd.DataFrame(dataClass)\n",
    "\n",
    "# Filtragem por CLASSE\n",
    "data_class_unacc = dataset.loc[(dataset['classs']=='unacc')]\n",
    "data_class_acc = dataset.loc[(dataset['classs']=='acc')]\n",
    "data_class_good = dataset.loc[(dataset['classs']=='good')]\n",
    "data_class_vgood = dataset.loc[(dataset['classs']=='vgood')]\n",
    "\n",
    "# Quantidade total de elementos por classe\n",
    "total_el_unacc = data_class_unacc['classs'].count()\n",
    "total_el_acc = data_class_acc['classs'].count()\n",
    "total_el_good = data_class_good['classs'].count()\n",
    "total_el_vgood = data_class_vgood['classs'].count()\n",
    "\n",
    "total_el_unacc,total_el_acc,total_el_good,total_el_vgood\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "431 432 432 432 1727\n"
     ]
    }
   ],
   "source": [
    "# MANIPULAÇAO DO DATAFRAME PELO ATRIBUTO BUYING\n",
    "\n",
    "# O PASSO DE FILTRAGEM A SEGUIR JA CONTEM FUNCAO IMPLEMENTADA\n",
    "# FIltragem dos BUYING = 'vhigh'\n",
    "data_vhigh=dataset.loc[(dataset['buying']=='vhigh')]\n",
    "\n",
    "# Filtragem dos BUYNG='high'\n",
    "data_high=dataset.loc[(dataset['buying']=='high')]\n",
    "\n",
    "# Filtragem dos BUYNG='med'\n",
    "data_med=dataset.loc[(dataset['buying']=='med')]\n",
    "\n",
    "# Filtragem dos BUYNG='low'\n",
    "data_low=dataset.loc[(dataset['buying']=='low')]\n",
    "\n",
    "# Filtragem dos BUYNG='vhigh' && CLASS='unacc'\n",
    "data_vhigh_unacc=dataset.loc[(dataset['buying']=='vhigh') & (dataset['classs']=='unacc')]\n",
    "\n",
    "# Filtragem dos BUYNG='high' && CLASS='unacc'\n",
    "data_high_unacc=dataset.loc[(dataset['buying']=='high') & (dataset['classs']=='unacc')]\n",
    "\n",
    "# Filtragem dos BUYNG='med' && CLASS='unacc'\n",
    "data_med_unacc=dataset.loc[(dataset['buying']=='med') & (dataset['classs']=='unacc')]\n",
    "\n",
    "# Filtragem dos BUYNG='low' && CLASS='unacc'\n",
    "data_low_unacc=dataset.loc[(dataset['buying']=='low') & (dataset['classs']=='unacc')]\n",
    "\n",
    "\n",
    "\n",
    "# Filtragem dos BUYNG='vhigh' && CLASS='acc'\n",
    "data_vhigh_acc=dataset.loc[(dataset['buying']=='vhigh') & (dataset['classs']=='acc')]\n",
    "\n",
    "# Filtragem dos BUYNG='high' && CLASS='acc'\n",
    "data_high_acc=dataset.loc[(dataset['buying']=='high') & (dataset['classs']=='acc')]\n",
    "\n",
    "# Filtragem dos BUYNG='med' && CLASS='acc'\n",
    "data_med_acc=dataset.loc[(dataset['buying']=='med') & (dataset['classs']=='acc')]\n",
    "\n",
    "# Filtragem dos BUYNG='low' && CLASS='acc'\n",
    "data_low_acc=dataset.loc[(dataset['buying']=='low') & (dataset['classs']=='acc')]\n",
    "\n",
    "\n",
    "\n",
    "# Filtragem dos BUYNG='vhigh' && CLASS='good'\n",
    "data_vhigh_good=dataset.loc[(dataset['buying']=='vhigh') & (dataset['classs']=='good')]\n",
    "\n",
    "# Filtragem dos BUYNG='high' && CLASS='good'\n",
    "data_high_good=dataset.loc[(dataset['buying']=='high') & (dataset['classs']=='good')]\n",
    "\n",
    "# Filtragem dos BUYNG='med' && CLASS='good'\n",
    "data_med_good=dataset.loc[(dataset['buying']=='med') & (dataset['classs']=='good')]\n",
    "\n",
    "# Filtragem dos BUYNG='low' && CLASS='good'\n",
    "data_low_good=dataset.loc[(dataset['buying']=='low') & (dataset['classs']=='good')]\n",
    "\n",
    "\n",
    "\n",
    "# Filtragem dos BUYNG='vhigh' && CLASS='vgood'\n",
    "data_vhigh_vgood=dataset.loc[(dataset['buying']=='vhigh') & (dataset['classs']=='vgood')]\n",
    "\n",
    "# Filtragem dos BUYNG='high' && CLASS='vgood'\n",
    "data_high_vgood=dataset.loc[(dataset['buying']=='high') & (dataset['classs']=='vgood')]\n",
    "\n",
    "# Filtragem dos BUYNG='med' && CLASS='vgood'\n",
    "data_med_vgood=dataset.loc[(dataset['buying']=='med') & (dataset['classs']=='vgood')]\n",
    "\n",
    "# Filtragem dos BUYNG='low' && CLASS='vgood'\n",
    "data_low_vgood=dataset.loc[(dataset['buying']=='low') & (dataset['classs']=='vgood')]\n",
    "\n",
    "\n",
    "\n",
    "# CONTAGEM DE ELEMENTOS\n",
    "# IMPLEMENTAÇÃO DA FUNCAO FINALIZADA\n",
    "\n",
    "# Quantidade total de elementos\n",
    "total_elementos = dataset['buying'].count()\n",
    "\n",
    "# Total vhigh\n",
    "total_vhigh = data_vhigh['buying'].count()\n",
    "\n",
    "# Total high\n",
    "total_high = data_high['buying'].count()\n",
    "\n",
    "# Total med\n",
    "total_med = data_med['buying'].count()\n",
    "\n",
    "# Total low \n",
    "total_low = data_low['buying'].count()\n",
    "\n",
    "# IMPLEMENTANDO\n",
    "# TABELA DE FREQUENCIA PARA BUYING/CLASS\n",
    "# Total vhigh p/ classe unacc\n",
    "total_vhigh_unacc = data_vhigh_unacc['buying'].count()\n",
    "\n",
    "# Total high p/ classe unacc\n",
    "total_high_unacc = data_high_unacc['buying'].count()\n",
    "\n",
    "# Total med p/ classe unacc\n",
    "total_med_unacc = data_med_unacc['buying'].count()\n",
    "\n",
    "# Total low p/ classe unacc\n",
    "total_low_unacc = data_low_unacc['buying'].count()\n",
    "\n",
    "\n",
    "# Total vhigh p/ classe acc\n",
    "total_vhigh_acc = data_vhigh_acc['buying'].count()\n",
    "\n",
    "# Total high p/ classe acc\n",
    "total_high_acc = data_high_acc['buying'].count()\n",
    "\n",
    "# Total med p/ classe acc\n",
    "total_med_acc = data_med_acc['buying'].count()\n",
    "\n",
    "# Total low p/ classe acc\n",
    "total_low_acc = data_low_acc['buying'].count()\n",
    "\n",
    "\n",
    "# Total vhigh p/ classe good\n",
    "total_vhigh_good = data_vhigh_good['buying'].count()\n",
    "\n",
    "# Total high p/ classe good\n",
    "total_high_good = data_high_good['buying'].count()\n",
    "\n",
    "# Total med p/ classe unacc\n",
    "total_med_good = data_med_good['buying'].count()\n",
    "\n",
    "# Total low p/ classe unacc\n",
    "total_low_good = data_low_good['buying'].count()\n",
    "\n",
    "\n",
    "# Total vhigh p/ classe vgood\n",
    "total_vhigh_vgood = data_vhigh_good['buying'].count()\n",
    "\n",
    "# Total high p/ classe vgood\n",
    "total_high_vgood = data_high_vgood['buying'].count()\n",
    "\n",
    "# Total med p/ classe unacc\n",
    "total_med_vgood = data_med_vgood['buying'].count()\n",
    "\n",
    "# Total low p/ classe unacc\n",
    "total_low_vgood = data_low_vgood['buying'].count()\n",
    "\n",
    "\n",
    "print(total_vhigh,total_high,total_med,total_low,total_elementos)\n",
    "# total_elementos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p_unacc_vhigh : 0.8329466357308586\n",
      "p_acc_vhigh : 0.16705336426914155\n",
      "p_good_vhigh : 0.0\n",
      "p_vgood_vhigh : 0.0\n"
     ]
    }
   ],
   "source": [
    "# NAIVE BAYES\n",
    "# FALTA IMPLEMENTAR FUNCOES QUE FAZEM ESSE BLOCO!\n",
    "\n",
    "# P(class|atrib) = [P(atri|class)*P(class)]/P(atrib)\n",
    "\n",
    "# P(ATRIBUTO/CLASS) : IMPLEMENTADO\n",
    "# P(atributo|uncc)\n",
    "p_vhigh_unacc = total_vhigh_unacc/total_el_unacc\n",
    "p_high_unacc = total_high_unacc/total_el_unacc\n",
    "p_med_unacc = total_med_unacc/total_el_unacc\n",
    "p_low_unacc = total_low_unacc/total_el_unacc\n",
    "\n",
    "# P(atributo|acc)\n",
    "p_vhigh_acc = total_vhigh_acc/total_el_acc\n",
    "p_high_acc = total_high_acc/total_el_acc\n",
    "p_med_acc = total_med_acc/total_el_acc\n",
    "p_low_acc = total_low_acc/total_el_acc\n",
    "\n",
    "# P(atributo|good)\n",
    "p_vhigh_good = total_vhigh_good/total_el_good\n",
    "p_high_good = total_high_good/total_el_good\n",
    "p_med_good = total_med_good/total_el_good\n",
    "p_low_good = total_low_good/total_el_good\n",
    "\n",
    "# P(atributo|vgood)\n",
    "p_vhigh_vgood = total_vhigh_vgood/total_el_vgood\n",
    "p_high_vgood = total_high_vgood/total_el_vgood\n",
    "p_med_vgood = total_med_vgood/total_el_vgood\n",
    "p_low_vgood = total_low_vgood/total_el_vgood\n",
    "\n",
    "# IMPLEMENTADO!\n",
    "# P(vhigh)\n",
    "p_vhigh = total_vhigh/total_elementos\n",
    "\n",
    "# P(high)\n",
    "p_high = total_high/total_elementos\n",
    "\n",
    "# P(med)\n",
    "p_med = total_med/total_elementos\n",
    "\n",
    "# P(low)\n",
    "p_low = total_low/total_elementos\n",
    "\n",
    "# IMPLEMENTADO\n",
    "# P(class)\n",
    "p_unacc = total_el_unacc/total_elementos\n",
    "p_acc = total_el_acc/total_elementos\n",
    "p_good = total_el_good/total_elementos\n",
    "p_vgood = total_el_vgood/total_elementos\n",
    "\n",
    "# P(uncc|vhigh) = \n",
    "p_unacc_vhigh = (p_vhigh_unacc * p_unacc)/(p_vhigh)\n",
    "\n",
    "# P(acc|vhigh)\n",
    "p_acc_vhigh = (p_vhigh_acc * p_acc)/(p_vhigh)\n",
    "\n",
    "# P(good|vhigh)\n",
    "p_good_vhigh = (p_vhigh_good * p_good)/(p_vhigh)\n",
    "\n",
    "# P(vgood|vhigh)\n",
    "p_vgood_vhigh = (p_vhigh_vgood * p_vgood)/(p_vhigh)\n",
    "\n",
    "#v_p_vhigh[]=p_unacc_vhigh,p_acc_vhigh,p_good_vhigh,p_vgood_vhigh\n",
    "#prob_test = max(v_p_vhigh)\n",
    "\n",
    "print((\"p_unacc_vhigh : {0}\\np_acc_vhigh : {1}\\np_good_vhigh : {2}\\np_vgood_vhigh : {3}\").format(p_unacc_vhigh,p_acc_vhigh,p_good_vhigh,p_vgood_vhigh))\n",
    "\n",
    "# print(p_high_unacc,p_high_acc,p_high_good,p_high_vgood)\n",
    "# print(total_vhigh,total_high,total_med,total_low,p_vhigh,p_high,p_med,p_low,total_elementos)\n",
    "\n",
    "# print(total_med_unacc, total_med_acc, total_med_good,total_med_vgood)\n",
    "# print(total_el_unacc, total_el_acc, total_el_good, total_el_vgood)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['unacc', 'acc', 'vgood', 'good'], dtype=object)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LISTA ELEMENTOS UNICOS DE UMA COLUNA\n",
    "teste=dataset.classs.unique()\n",
    "teste\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 0.83294663573085859, 1: 0.16705336426914155, 2: 0.0, 3: 0.0, 4: 0.74999999999999989, 5: 0.25, 6: 0.0, 7: 0.0, 8: 0.62037037037037035, 9: 0.26620370370370372, 10: 0.060185185185185182, 11: 0.053240740740740741, 12: 0.5972222222222221, 13: 0.20601851851851855, 14: 0.090277777777777776, 15: 0.10648148148148148, 16: 0.83294663573085859, 17: 0.16705336426914155, 18: 0.0, 19: 0.0, 20: 0.72685185185185186, 21: 0.24305555555555555, 22: 0.030092592592592591, 23: 0.0, 24: 0.62037037037037035, 25: 0.26620370370370372, 26: 0.060185185185185182, 27: 0.053240740740740741, 28: 0.62037037037037035, 29: 0.21296296296296299, 30: 0.060185185185185182, 31: 0.10648148148148148, 32: 0.75406032482598606, 33: 0.18793503480278423, 34: 0.023201856148491878, 35: 0.034802784222737825, 36: 0.69444444444444453, 37: 0.22916666666666669, 38: 0.034722222222222224, 39: 0.041666666666666671, 40: 0.67592592592592593, 41: 0.23611111111111113, 42: 0.046296296296296294, 43: 0.041666666666666671, 44: 0.67592592592592593, 45: 0.23611111111111113, 46: 0.046296296296296294, 47: 0.041666666666666671, 48: 1.0, 49: 0.0, 50: 0.0, 51: 0.0, 52: 0.54166666666666663, 53: 0.34375, 54: 0.052083333333333336, 55: 0.0625, 56: 0.55902777777777779, 57: 0.32291666666666663, 58: 0.060763888888888874, 59: 0.057291666666666664, 60: 0.78086956521739126, 61: 0.18260869565217391, 62: 0.0, 63: 0.036521739130434785, 64: 0.68055555555555558, 65: 0.234375, 66: 0.043402777777777776, 67: 0.041666666666666664, 68: 0.63888888888888884, 69: 0.25, 70: 0.069444444444444434, 71: 0.041666666666666664, 72: 0.61979166666666663, 73: 0.31249999999999994, 74: 0.0, 75: 0.067708333333333329, 76: 0.48090277777777768, 77: 0.35416666666666669, 78: 0.11284722222222221, 79: 0.052083333333333336, 80: 1.0, 81: 0.0, 82: 0.0, 83: 0.0} {0: 0.83294663573085859, 1: 0.74999999999999989, 2: 0.62037037037037035, 3: 0.5972222222222221, 4: 0.83294663573085859, 5: 0.72685185185185186, 6: 0.62037037037037035, 7: 0.62037037037037035, 8: 0.75406032482598606, 9: 0.69444444444444453, 10: 0.67592592592592593, 11: 0.67592592592592593, 12: 1.0, 13: 0.54166666666666663, 14: 0.55902777777777779, 15: 0.78086956521739126, 16: 0.68055555555555558, 17: 0.63888888888888884, 18: 0.61979166666666663, 19: 0.48090277777777768, 20: 1.0}\n"
     ]
    }
   ],
   "source": [
    "# ALGUMAS FUNCOES JA PRONTAS! FALTA FAZER O PASSO DA CONTAGEM AGORA.\n",
    "\n",
    "\n",
    "# # MANIPULAÇÃO DO DATAFRAME PELA CLASSE\n",
    "\n",
    "# dataClass=pd.value_counts(dataset['classs'])\n",
    "# dataframeClass=pd.DataFrame(dataClass)\n",
    "\n",
    "# Funcao abaixo esta funcionando!\n",
    "# A classe retorna um dicionario de DATAFRAMES e Total elementos de cada Dataframe\n",
    "# Para acessar primeiro dataframe: separatedByClass[0]\n",
    "# def separatedByClass(dataset):\n",
    "#     class_element_v = dataset.classs.unique()\n",
    "#     separatedByClass = {}\n",
    "#     total_el_class = {}\n",
    "#     for i in range(0,4):\n",
    "#         separatedByClass[i] = dataset.loc[(dataset['classs']==class_element_v[i])]\n",
    "#         total_el_class[i] = separatedByClass[i]['classs'].count()\n",
    "#     return separetedByClass, total_el_class\n",
    "\n",
    "\n",
    "\n",
    "# MANIPULAÇAO DO DATAFRAME PELO ATRIBUTO BUYING\n",
    "\n",
    "# A funcao a seguir retorna a filtragem por atributos de cada coluna\n",
    "# Retorna um dicionario com 21 elementos (0 a 20)\n",
    "# def separatedByFeature(dataset):\n",
    "#     data_columns = dataset.columns\n",
    "#     len_columns = len(data_columns)-1\n",
    "#     separatedByFeature = {}\n",
    "#     total_el_features = {}\n",
    "#     k=0\n",
    "#     for i in range(0,len_columns):\n",
    "#         feature = dataset[data_columns[i]].unique() # Elementos de cada Feature\n",
    "#         len_feature = len(feature)\n",
    "#         for j in range(0,len_feature):\n",
    "#             data_filter_feature = dataset.loc[(dataset[data_columns[i]] == feature[j])] \n",
    "#             separatedByFeature[k] = data_filter_feature\n",
    "#             total_el_features[k] = separatedByFeature[k][data_columns[i]].count()\n",
    "#             k=k+1\n",
    "#     return separatedByFeature, total_el_features\n",
    "\n",
    "\n",
    "# A FUNCAO ABAIXO RETORNA UM DIC DE 84 ITENS\n",
    "# É REALIZADO UMA FILTRAGEM DE CADA FEATURE & CADA CLASS. LOGO, SAO 4 DATAFRAMES PARA CADA ELEMENTO DE FEATURE 21*4\n",
    "# EXEMPLO: data_vhigh_unacc=dataset.loc[(dataset['buying']=='vhigh') & (dataset['classs']=='unacc')]\n",
    "# def separatedByFeatureClass(dic_separatedByFeature)\n",
    "#     separatedByFeature = dic_separatedByFeature\n",
    "#     class_element_v = separatedByFeature[0].classs.unique()\n",
    "#     len_separatedByFeature = len(separatedByFeature)\n",
    "#     separatedByFeatureClass = {}\n",
    "#     total_el_feature_class = {}\n",
    "#     k = 0\n",
    "#     for i in range (0,len_separatedByFeature):\n",
    "#         if (i>=0 and i<16):\n",
    "#             data_filter_feature_class = separatedByFeature[i].loc[(separatedByFeature[i]['classs']==class_element_v[0])]\n",
    "#             separatedByFeatureClass[k] = data_filter_feature_class\n",
    "#             total_el_feature_class[k] = separatedByFeatureClass[k]['buying'].count()\n",
    "#             k=k+1\n",
    "#             data_filter_feature_class = separatedByFeature[i].loc[(separatedByFeature[i]['classs']==class_element_v[1])]\n",
    "#             separatedByFeatureClass[k] = data_filter_feature_class\n",
    "#             total_el_feature_class[k] = separatedByFeatureClass[k]['buying'].count()\n",
    "#             k=k+1\n",
    "#             data_filter_feature_class = separatedByFeature[i].loc[(separatedByFeature[i]['classs']==class_element_v[2])]\n",
    "#             separatedByFeatureClass[k] = data_filter_feature_class\n",
    "#             total_el_feature_class[k] = separatedByFeatureClass[k]['buying'].count()\n",
    "#             k=k+1\n",
    "#             data_filter_feature_class = separatedByFeature[i].loc[(separatedByFeature[i]['classs']==class_element_v[3])]\n",
    "#             separatedByFeatureClass[k] = data_filter_feature_class\n",
    "#             total_el_feature_class[k] = separatedByFeatureClass[k]['buying'].count()\n",
    "#             k=k+1\n",
    "#         elif (i>=16 and i<32):\n",
    "#             data_filter_feature_class = separatedByFeature[i].loc[(separatedByFeature[i]['classs']==class_element_v[0])]\n",
    "#             separatedByFeatureClass[k] = data_filter_feature_class\n",
    "#             total_el_feature_class[k] = separatedByFeatureClass[k]['maint'].count()\n",
    "#             k=k+1\n",
    "#             data_filter_feature_class = separatedByFeature[i].loc[(separatedByFeature[i]['classs']==class_element_v[1])]\n",
    "#             separatedByFeatureClass[k] = data_filter_feature_class\n",
    "#             total_el_feature_class[k] = separatedByFeatureClass[k]['maint'].count()\n",
    "#             k=k+1\n",
    "#             data_filter_feature_class = separatedByFeature[i].loc[(separatedByFeature[i]['classs']==class_element_v[2])]\n",
    "#             separatedByFeatureClass[k] = data_filter_feature_class\n",
    "#             total_el_feature_class[k] = separatedByFeatureClass[k]['maint'].count()\n",
    "#             k=k+1\n",
    "#             data_filter_feature_class = separatedByFeature[i].loc[(separatedByFeature[i]['classs']==class_element_v[3])]\n",
    "#             separatedByFeatureClass[k] = data_filter_feature_class\n",
    "#             total_el_feature_class[k] = separatedByFeatureClass[k]['maint'].count()\n",
    "#             k=k+1\n",
    "#         elif (i>=32 and i<48):\n",
    "#             data_filter_feature_class = separatedByFeature[i].loc[(separatedByFeature[i]['classs']==class_element_v[0])]\n",
    "#             separatedByFeatureClass[k] = data_filter_feature_class\n",
    "#             total_el_feature_class[k] = separatedByFeatureClass[k]['doors'].count()\n",
    "#             k=k+1\n",
    "#             data_filter_feature_class = separatedByFeature[i].loc[(separatedByFeature[i]['classs']==class_element_v[1])]\n",
    "#             separatedByFeatureClass[k] = data_filter_feature_class\n",
    "#             total_el_feature_class[k] = separatedByFeatureClass[k]['doors'].count()\n",
    "#             k=k+1\n",
    "#             data_filter_feature_class = separatedByFeature[i].loc[(separatedByFeature[i]['classs']==class_element_v[2])]\n",
    "#             separatedByFeatureClass[k] = data_filter_feature_class\n",
    "#             total_el_feature_class[k] = separatedByFeatureClass[k]['doors'].count()\n",
    "#             k=k+1\n",
    "#             data_filter_feature_class = separatedByFeature[i].loc[(separatedByFeature[i]['classs']==class_element_v[3])]\n",
    "#             separatedByFeatureClass[k] = data_filter_feature_class\n",
    "#             total_el_feature_class[k] = separatedByFeatureClass[k]['doors'].count()\n",
    "#             k=k+1\n",
    "#         elif (i>=48 and i<60):\n",
    "#             data_filter_feature_class = separatedByFeature[i].loc[(separatedByFeature[i]['classs']==class_element_v[0])]\n",
    "#             separatedByFeatureClass[k] = data_filter_feature_class\n",
    "#             total_el_feature_class[k] = separatedByFeatureClass[k]['persons'].count()\n",
    "#             k=k+1\n",
    "#             data_filter_feature_class = separatedByFeature[i].loc[(separatedByFeature[i]['classs']==class_element_v[1])]\n",
    "#             separatedByFeatureClass[k] = data_filter_feature_class\n",
    "#             total_el_feature_class[k] = separatedByFeatureClass[k]['persons'].count()\n",
    "#             k=k+1\n",
    "#             data_filter_feature_class = separatedByFeature[i].loc[(separatedByFeature[i]['classs']==class_element_v[2])]\n",
    "#             separatedByFeatureClass[k] = data_filter_feature_class\n",
    "#             total_el_feature_class[k] = separatedByFeatureClass[k]['persons'].count()\n",
    "#             k=k+1\n",
    "#             data_filter_feature_class = separatedByFeature[i].loc[(separatedByFeature[i]['classs']==class_element_v[3])]\n",
    "#             separatedByFeatureClass[k] = data_filter_feature_class\n",
    "#             total_el_feature_class[k] = separatedByFeatureClass[k]['persons'].count()\n",
    "#             k=k+1\n",
    "#         elif (i>=60 and i<72):\n",
    "#             data_filter_feature_class = separatedByFeature[i].loc[(separatedByFeature[i]['classs']==class_element_v[0])]\n",
    "#             separatedByFeatureClass[k] = data_filter_feature_class\n",
    "#             total_el_feature_class[k] = separatedByFeatureClass[k]['lug_boot'].count()\n",
    "#             k=k+1\n",
    "#             data_filter_feature_class = separatedByFeature[i].loc[(separatedByFeature[i]['classs']==class_element_v[1])]\n",
    "#             separatedByFeatureClass[k] = data_filter_feature_class\n",
    "#             total_el_feature_class[k] = separatedByFeatureClass[k]['lug_boot'].count()\n",
    "#             k=k+1\n",
    "#             data_filter_feature_class = separatedByFeature[i].loc[(separatedByFeature[i]['classs']==class_element_v[2])]\n",
    "#             separatedByFeatureClass[k] = data_filter_feature_class\n",
    "#             total_el_feature_class[k] = separatedByFeatureClass[k]['lug_boot'].count()\n",
    "#             k=k+1\n",
    "#             data_filter_feature_class = separatedByFeature[i].loc[(separatedByFeature[i]['classs']==class_element_v[3])]\n",
    "#             separatedByFeatureClass[k] = data_filter_feature_class\n",
    "#             total_el_feature_class[k] = separatedByFeatureClass[k]['lug_boot'].count()\n",
    "#             k=k+1\n",
    "#         elif (i>=72 and i<len_separatedByFeature):\n",
    "#             data_filter_feature_class = separatedByFeature[i].loc[(separatedByFeature[i]['classs']==class_element_v[0])]\n",
    "#             separatedByFeatureClass[k] = data_filter_feature_class\n",
    "#             total_el_feature_class[k] = separatedByFeatureClass[k]['lug_boot'].count()\n",
    "#             k=k+1\n",
    "#             data_filter_feature_class = separatedByFeature[i].loc[(separatedByFeature[i]['classs']==class_element_v[1])]\n",
    "#             separatedByFeatureClass[k] = data_filter_feature_class\n",
    "#             total_el_feature_class[k] = separatedByFeatureClass[k]['lug_boot'].count()\n",
    "#             k=k+1\n",
    "#             data_filter_feature_class = separatedByFeature[i].loc[(separatedByFeature[i]['classs']==class_element_v[2])]\n",
    "#             separatedByFeatureClass[k] = data_filter_feature_class\n",
    "#             total_el_feature_class[k] = separatedByFeatureClass[k]['lug_boot'].count()\n",
    "#             k=k+1\n",
    "#             data_filter_feature_class = separatedByFeature[i].loc[(separatedByFeature[i]['classs']==class_element_v[3])]\n",
    "#             separatedByFeatureClass[k] = data_filter_feature_class\n",
    "#             total_el_feature_class[k] = separatedByFeatureClass[k]['lug_boot'].count()\n",
    "#             k=k+1\n",
    "#     return separatedByFeatureClass, total_el_feature_class\n",
    "\n",
    "\n",
    "# A função a seguir retorna a probabilidade P(feature/class)\n",
    "# def p_FeatureClass(dic_total_el_feature_class,dic_total_el_class):\n",
    "#     total_el_feature_class = dic_total_el_feature_class\n",
    "#     total_el_class = dic_total_el_class\n",
    "#     p_feature_class = {}\n",
    "#     k=0\n",
    "#     while (k>=0 and k<16):\n",
    "#         p_feature_class[k] = total_el_feature_class[k]/total_el_class[0]\n",
    "#         k=k+1\n",
    "#         p_feature_class[k] = total_el_feature_class[k]/total_el_class[1]\n",
    "#         k=k+1\n",
    "#         p_feature_class[k] = total_el_feature_class[k]/total_el_class[2]\n",
    "#         k=k+1\n",
    "#         p_feature_class[k] = total_el_feature_class[k]/total_el_class[3]\n",
    "#         k=k+1\n",
    "#     while (k>=16 and k<32):\n",
    "#         p_feature_class[k] = total_el_feature_class[k]/total_el_class[0]\n",
    "#         k=k+1\n",
    "#         p_feature_class[k] = total_el_feature_class[k]/total_el_class[1]\n",
    "#         k=k+1\n",
    "#         p_feature_class[k] = total_el_feature_class[k]/total_el_class[2]\n",
    "#         k=k+1\n",
    "#         p_feature_class[k] = total_el_feature_class[k]/total_el_class[3]\n",
    "#         k=k+1   \n",
    "#     while (k>=32 and k<48):\n",
    "#         p_feature_class[k] = total_el_feature_class[k]/total_el_class[0]\n",
    "#         k=k+1\n",
    "#         p_feature_class[k] = total_el_feature_class[k]/total_el_class[1]\n",
    "#         k=k+1\n",
    "#         p_feature_class[k] = total_el_feature_class[k]/total_el_class[2]\n",
    "#         k=k+1\n",
    "#         p_feature_class[k] = total_el_feature_class[k]/total_el_class[3]\n",
    "#         k=k+1  \n",
    "#     while (k>=48 and k<60):\n",
    "#         p_feature_class[k] = total_el_feature_class[k]/total_el_class[0]\n",
    "#         k=k+1\n",
    "#         p_feature_class[k] = total_el_feature_class[k]/total_el_class[1]\n",
    "#         k=k+1\n",
    "#         p_feature_class[k] = total_el_feature_class[k]/total_el_class[2]\n",
    "#         k=k+1\n",
    "#         p_feature_class[k] = total_el_feature_class[k]/total_el_class[3]\n",
    "#         k=k+1 \n",
    "#     while (k>=60 and k<72):\n",
    "#         p_feature_class[k] = total_el_feature_class[k]/total_el_class[0]\n",
    "#         k=k+1\n",
    "#         p_feature_class[k] = total_el_feature_class[k]/total_el_class[1]\n",
    "#         k=k+1\n",
    "#         p_feature_class[k] = total_el_feature_class[k]/total_el_class[2]\n",
    "#         k=k+1\n",
    "#         p_feature_class[k] = total_el_feature_class[k]/total_el_class[3]\n",
    "#         k=k+1 \n",
    "#     while (k>=72 and k<84):\n",
    "#         p_feature_class[k] = total_el_feature_class[k]/total_el_class[0]\n",
    "#         k=k+1\n",
    "#         p_feature_class[k] = total_el_feature_class[k]/total_el_class[1]\n",
    "#         k=k+1\n",
    "#         p_feature_class[k] = total_el_feature_class[k]/total_el_class[2]\n",
    "#         k=k+1\n",
    "#         p_feature_class[k] = total_el_feature_class[k]/total_el_class[3]\n",
    "#         k=k+1\n",
    "#     return p_feature_class\n",
    "\n",
    "# A funcao a seguir retorna o P(feature) ou P(class)\n",
    "# def p_Features(dic_total_el_features):\n",
    "#     total_el_features = dic_total_el_features\n",
    "#     p_feature = {}\n",
    "#     len_features = len(total_el_features)\n",
    "#     total_elements=0\n",
    "#     for i in range (0,4):\n",
    "#         total_elements = total_elements+total_el_features[i]\n",
    "\n",
    "#     for i in range(0,len_features):\n",
    "#         p_feature[i] = total_el_features[i]/total_elements\n",
    "#     return p_feature\n",
    "\n",
    "# def main():\n",
    "#     filename=dataset\n",
    "#     nhae = separateByClass(filename)\n",
    "#     print(nhae)\n",
    "# if __name__ == \"__main__\":\n",
    "#     main()\n",
    "\n",
    "############################################## INICIO TESTAR FUNCOES #####################################################\n",
    "\n",
    "class_element_v = dataset.classs.unique()\n",
    "separatedByClass = {}\n",
    "total_el_class = {}\n",
    "for i in range(0,4):\n",
    "    separatedByClass[i] = dataset.loc[(dataset['classs']==class_element_v[i])]\n",
    "    total_el_class[i] = separatedByClass[i]['classs'].count()\n",
    "\n",
    "data_columns = dataset.columns\n",
    "len_columns = len(data_columns)-1\n",
    "separatedByFeature = {}\n",
    "total_el_features = {}\n",
    "k=0\n",
    "for i in range(0,len_columns):\n",
    "    feature = dataset[data_columns[i]].unique() # Elementos de cada Feature\n",
    "    len_feature = len(feature)\n",
    "    for j in range(0,len_feature):\n",
    "        data_filter_feature = dataset.loc[(dataset[data_columns[i]] == feature[j])] \n",
    "        separatedByFeature[k] = data_filter_feature\n",
    "        total_el_features[k] = separatedByFeature[k][data_columns[i]].count()\n",
    "        k=k+1\n",
    "\n",
    "len_dic = len(separatedByFeature)\n",
    "# data_columns = dataset.columns\n",
    "# len_columns = len(data_columns)-1\n",
    "separatedByFeatureClass = {}\n",
    "total_el_feature_class = {}\n",
    "k = 0\n",
    "for i in range (0,len_dic):\n",
    "    if (i>=0 and i<16):\n",
    "        data_filter_feature_class = separatedByFeature[i].loc[(separatedByFeature[i]['classs']==class_element_v[0])]\n",
    "        separatedByFeatureClass[k] = data_filter_feature_class\n",
    "        total_el_feature_class[k] = separatedByFeatureClass[k]['buying'].count()\n",
    "        k=k+1\n",
    "        data_filter_feature_class = separatedByFeature[i].loc[(separatedByFeature[i]['classs']==class_element_v[1])]\n",
    "        separatedByFeatureClass[k] = data_filter_feature_class\n",
    "        total_el_feature_class[k] = separatedByFeatureClass[k]['buying'].count()\n",
    "        k=k+1\n",
    "        data_filter_feature_class = separatedByFeature[i].loc[(separatedByFeature[i]['classs']==class_element_v[2])]\n",
    "        separatedByFeatureClass[k] = data_filter_feature_class\n",
    "        total_el_feature_class[k] = separatedByFeatureClass[k]['buying'].count()\n",
    "        k=k+1\n",
    "        data_filter_feature_class = separatedByFeature[i].loc[(separatedByFeature[i]['classs']==class_element_v[3])]\n",
    "        separatedByFeatureClass[k] = data_filter_feature_class\n",
    "        total_el_feature_class[k] = separatedByFeatureClass[k]['buying'].count()\n",
    "        k=k+1\n",
    "    elif (i>=16 and i<32):\n",
    "        data_filter_feature_class = separatedByFeature[i].loc[(separatedByFeature[i]['classs']==class_element_v[0])]\n",
    "        separatedByFeatureClass[k] = data_filter_feature_class\n",
    "        total_el_feature_class[k] = separatedByFeatureClass[k]['maint'].count()\n",
    "        k=k+1\n",
    "        data_filter_feature_class = separatedByFeature[i].loc[(separatedByFeature[i]['classs']==class_element_v[1])]\n",
    "        separatedByFeatureClass[k] = data_filter_feature_class\n",
    "        total_el_feature_class[k] = separatedByFeatureClass[k]['maint'].count()\n",
    "        k=k+1\n",
    "        data_filter_feature_class = separatedByFeature[i].loc[(separatedByFeature[i]['classs']==class_element_v[2])]\n",
    "        separatedByFeatureClass[k] = data_filter_feature_class\n",
    "        total_el_feature_class[k] = separatedByFeatureClass[k]['maint'].count()\n",
    "        k=k+1\n",
    "        data_filter_feature_class = separatedByFeature[i].loc[(separatedByFeature[i]['classs']==class_element_v[3])]\n",
    "        separatedByFeatureClass[k] = data_filter_feature_class\n",
    "        total_el_feature_class[k] = separatedByFeatureClass[k]['maint'].count()\n",
    "        k=k+1\n",
    "    elif (i>=32 and i<48):\n",
    "#         print(k)\n",
    "        data_filter_feature_class = separatedByFeature[i].loc[(separatedByFeature[i]['classs']==class_element_v[0])]\n",
    "        separatedByFeatureClass[k] = data_filter_feature_class\n",
    "        total_el_feature_class[k] = separatedByFeatureClass[k]['doors'].count()\n",
    "        k=k+1\n",
    "        data_filter_feature_class = separatedByFeature[i].loc[(separatedByFeature[i]['classs']==class_element_v[1])]\n",
    "        separatedByFeatureClass[k] = data_filter_feature_class\n",
    "        total_el_feature_class[k] = separatedByFeatureClass[k]['doors'].count()\n",
    "        k=k+1\n",
    "        data_filter_feature_class = separatedByFeature[i].loc[(separatedByFeature[i]['classs']==class_element_v[2])]\n",
    "        separatedByFeatureClass[k] = data_filter_feature_class\n",
    "        total_el_feature_class[k] = separatedByFeatureClass[k]['doors'].count()\n",
    "        k=k+1\n",
    "        data_filter_feature_class = separatedByFeature[i].loc[(separatedByFeature[i]['classs']==class_element_v[3])]\n",
    "        separatedByFeatureClass[k] = data_filter_feature_class\n",
    "        total_el_feature_class[k] = separatedByFeatureClass[k]['doors'].count()\n",
    "        k=k+1\n",
    "    elif (i>=48 and i<60):\n",
    "        data_filter_feature_class = separatedByFeature[i].loc[(separatedByFeature[i]['classs']==class_element_v[0])]\n",
    "        separatedByFeatureClass[k] = data_filter_feature_class\n",
    "        total_el_feature_class[k] = separatedByFeatureClass[k]['persons'].count()\n",
    "        k=k+1\n",
    "        data_filter_feature_class = separatedByFeature[i].loc[(separatedByFeature[i]['classs']==class_element_v[1])]\n",
    "        separatedByFeatureClass[k] = data_filter_feature_class\n",
    "        total_el_feature_class[k] = separatedByFeatureClass[k]['persons'].count()\n",
    "        k=k+1\n",
    "        data_filter_feature_class = separatedByFeature[i].loc[(separatedByFeature[i]['classs']==class_element_v[2])]\n",
    "        separatedByFeatureClass[k] = data_filter_feature_class\n",
    "        total_el_feature_class[k] = separatedByFeatureClass[k]['persons'].count()\n",
    "        k=k+1\n",
    "        data_filter_feature_class = separatedByFeature[i].loc[(separatedByFeature[i]['classs']==class_element_v[3])]\n",
    "        separatedByFeatureClass[k] = data_filter_feature_class\n",
    "        total_el_feature_class[k] = separatedByFeatureClass[k]['persons'].count()\n",
    "        k=k+1\n",
    "    elif (i>=60 and i<72):\n",
    "        data_filter_feature_class = separatedByFeature[i].loc[(separatedByFeature[i]['classs']==class_element_v[0])]\n",
    "        separatedByFeatureClass[k] = data_filter_feature_class\n",
    "        total_el_feature_class[k] = separatedByFeatureClass[k]['lug_boot'].count()\n",
    "        k=k+1\n",
    "        data_filter_feature_class = separatedByFeature[i].loc[(separatedByFeature[i]['classs']==class_element_v[1])]\n",
    "        separatedByFeatureClass[k] = data_filter_feature_class\n",
    "        total_el_feature_class[k] = separatedByFeatureClass[k]['lug_boot'].count()\n",
    "        k=k+1\n",
    "        data_filter_feature_class = separatedByFeature[i].loc[(separatedByFeature[i]['classs']==class_element_v[2])]\n",
    "        separatedByFeatureClass[k] = data_filter_feature_class\n",
    "        total_el_feature_class[k] = separatedByFeatureClass[k]['lug_boot'].count()\n",
    "        k=k+1\n",
    "        data_filter_feature_class = separatedByFeature[i].loc[(separatedByFeature[i]['classs']==class_element_v[3])]\n",
    "        separatedByFeatureClass[k] = data_filter_feature_class\n",
    "        total_el_feature_class[k] = separatedByFeatureClass[k]['lug_boot'].count()\n",
    "        k=k+1\n",
    "    elif (i>=72 and i<len_dic):\n",
    "        data_filter_feature_class = separatedByFeature[i].loc[(separatedByFeature[i]['classs']==class_element_v[0])]\n",
    "        separatedByFeatureClass[k] = data_filter_feature_class\n",
    "        total_el_feature_class[k] = separatedByFeatureClass[k]['lug_boot'].count()\n",
    "        k=k+1\n",
    "        data_filter_feature_class = separatedByFeature[i].loc[(separatedByFeature[i]['classs']==class_element_v[1])]\n",
    "        separatedByFeatureClass[k] = data_filter_feature_class\n",
    "        total_el_feature_class[k] = separatedByFeatureClass[k]['lug_boot'].count()\n",
    "        k=k+1\n",
    "        data_filter_feature_class = separatedByFeature[i].loc[(separatedByFeature[i]['classs']==class_element_v[2])]\n",
    "        separatedByFeatureClass[k] = data_filter_feature_class\n",
    "        total_el_feature_class[k] = separatedByFeatureClass[k]['lug_boot'].count()\n",
    "        k=k+1\n",
    "        data_filter_feature_class = separatedByFeature[i].loc[(separatedByFeature[i]['classs']==class_element_v[3])]\n",
    "        separatedByFeatureClass[k] = data_filter_feature_class\n",
    "        total_el_feature_class[k] = separatedByFeatureClass[k]['lug_boot'].count()\n",
    "        k=k+1\n",
    "\n",
    "p_feature_class = {}\n",
    "p_max_feature_class = {}\n",
    "k=0\n",
    "while (k>=0 and k<16):\n",
    "    p_feature_class[k] = total_el_feature_class[k]/total_el_class[0]\n",
    "    k=k+1\n",
    "    p_feature_class[k] = total_el_feature_class[k]/total_el_class[1]\n",
    "    k=k+1\n",
    "    p_feature_class[k] = total_el_feature_class[k]/total_el_class[2]\n",
    "    k=k+1\n",
    "    p_feature_class[k] = total_el_feature_class[k]/total_el_class[3]\n",
    "    k=k+1\n",
    "while (k>=16 and k<32):\n",
    "    p_feature_class[k] = total_el_feature_class[k]/total_el_class[0]\n",
    "    k=k+1\n",
    "    p_feature_class[k] = total_el_feature_class[k]/total_el_class[1]\n",
    "    k=k+1\n",
    "    p_feature_class[k] = total_el_feature_class[k]/total_el_class[2]\n",
    "    k=k+1\n",
    "    p_feature_class[k] = total_el_feature_class[k]/total_el_class[3]\n",
    "    k=k+1   \n",
    "while (k>=32 and k<48):\n",
    "    p_feature_class[k] = total_el_feature_class[k]/total_el_class[0]\n",
    "    k=k+1\n",
    "    p_feature_class[k] = total_el_feature_class[k]/total_el_class[1]\n",
    "    k=k+1\n",
    "    p_feature_class[k] = total_el_feature_class[k]/total_el_class[2]\n",
    "    k=k+1\n",
    "    p_feature_class[k] = total_el_feature_class[k]/total_el_class[3]\n",
    "    k=k+1  \n",
    "while (k>=48 and k<60):\n",
    "    p_feature_class[k] = total_el_feature_class[k]/total_el_class[0]\n",
    "    k=k+1\n",
    "    p_feature_class[k] = total_el_feature_class[k]/total_el_class[1]\n",
    "    k=k+1\n",
    "    p_feature_class[k] = total_el_feature_class[k]/total_el_class[2]\n",
    "    k=k+1\n",
    "    p_feature_class[k] = total_el_feature_class[k]/total_el_class[3]\n",
    "    k=k+1 \n",
    "while (k>=60 and k<72):\n",
    "    p_feature_class[k] = total_el_feature_class[k]/total_el_class[0]\n",
    "    k=k+1\n",
    "    p_feature_class[k] = total_el_feature_class[k]/total_el_class[1]\n",
    "    k=k+1\n",
    "    p_feature_class[k] = total_el_feature_class[k]/total_el_class[2]\n",
    "    k=k+1\n",
    "    p_feature_class[k] = total_el_feature_class[k]/total_el_class[3]\n",
    "    k=k+1 \n",
    "while (k>=72 and k<84):\n",
    "    p_feature_class[k] = total_el_feature_class[k]/total_el_class[0]\n",
    "    k=k+1\n",
    "    p_feature_class[k] = total_el_feature_class[k]/total_el_class[1]\n",
    "    k=k+1\n",
    "    p_feature_class[k] = total_el_feature_class[k]/total_el_class[2]\n",
    "    k=k+1\n",
    "    p_feature_class[k] = total_el_feature_class[k]/total_el_class[3]\n",
    "    k=k+1 \n",
    "# print(total_el_feature_class,k)\n",
    "\n",
    "p_feature = {}\n",
    "len_features = len(total_el_features)\n",
    "total_elements=0\n",
    "for i in range (0,4):\n",
    "    total_elements = total_elements+total_el_features[i]\n",
    "\n",
    "for i in range(0,len_features):\n",
    "    p_feature[i] = total_el_features[i]/total_elements\n",
    "\n",
    "# print(total_el_features)\n",
    "\n",
    "\n",
    "p_class = {}\n",
    "len_class = len(total_el_class)\n",
    "total_elements=0\n",
    "for i in range (0,4):\n",
    "    total_elements = total_elements+total_el_class[i]\n",
    "\n",
    "for i in range(0,len_class):\n",
    "    p_class[i] = total_el_class[i]/total_elements\n",
    "# print(p_class)\n",
    "\n",
    "\n",
    "##### \n",
    "\n",
    "# print(p_feature_class)\n",
    "\n",
    "###### FALTA PRODUTORIO E MULTIPLICAR PELA CLASSE 4############EI##\n",
    "##### TALVEZ AINDA FALTE IMPLEMENTAR OUTRO MAX PARA A FEATURE!########\n",
    "\n",
    "\n",
    "# for i in range(1,10,2):\n",
    "#     print(i)\n",
    "\n",
    "p_class_feature = {}\n",
    "p_class_feature1 = {}\n",
    "maxx=0\n",
    "c=0\n",
    "for k in range(0,4):\n",
    "    p_class_feature[k] = (p_feature_class[k]*p_class[c])/p_feature[0]\n",
    "    if (p_class_feature[k]>maxx):\n",
    "        maxx = p_class_feature[k]\n",
    "    p_class_feature1[0] = maxx\n",
    "    c=c+1\n",
    "\n",
    "maxx=0\n",
    "c=0\n",
    "for k in range(4,8):\n",
    "    p_class_feature[k] = (p_feature_class[k]*p_class[c])/p_feature[1]\n",
    "    if (p_class_feature[k]>maxx):\n",
    "        maxx = p_class_feature[k]\n",
    "    p_class_feature1[1] = maxx\n",
    "    c=c+1\n",
    "\n",
    "maxx=0\n",
    "c=0\n",
    "for k in range(8,12):\n",
    "    p_class_feature[k] = (p_feature_class[k]*p_class[c])/p_feature[2]\n",
    "    if (p_class_feature[k]>maxx):\n",
    "        maxx = p_class_feature[k]\n",
    "    p_class_feature1[2] = maxx\n",
    "    c=c+1\n",
    "maxx=0\n",
    "c=0\n",
    "for k in range(12,16):\n",
    "    p_class_feature[k] = (p_feature_class[k]*p_class[c])/p_feature[3]\n",
    "    if (p_class_feature[k]>maxx):\n",
    "        maxx = p_class_feature[k]\n",
    "    p_class_feature1[3] = maxx\n",
    "    c=c+1\n",
    "maxx=0\n",
    "c=0\n",
    "for k in range(16,20):\n",
    "    p_class_feature[k] = (p_feature_class[k]*p_class[c])/p_feature[4]\n",
    "    if (p_class_feature[k]>maxx):\n",
    "        maxx = p_class_feature[k]\n",
    "    p_class_feature1[4] = maxx\n",
    "    c=c+1\n",
    "maxx=0\n",
    "c=0\n",
    "for k in range(20,24):\n",
    "    p_class_feature[k] = (p_feature_class[k]*p_class[c])/p_feature[5]\n",
    "    if (p_class_feature[k]>maxx):\n",
    "        maxx = p_class_feature[k]\n",
    "    p_class_feature1[5] = maxx\n",
    "    c=c+1\n",
    "maxx=0\n",
    "c=0\n",
    "for k in range(24,28):\n",
    "    p_class_feature[k] = (p_feature_class[k]*p_class[c])/p_feature[6]\n",
    "    if (p_class_feature[k]>maxx):\n",
    "        maxx = p_class_feature[k]\n",
    "    p_class_feature1[6] = maxx\n",
    "    c=c+1\n",
    "maxx=0\n",
    "c=0\n",
    "for k in range(28,32):\n",
    "    p_class_feature[k] = (p_feature_class[k]*p_class[c])/p_feature[7]\n",
    "    if (p_class_feature[k]>maxx):\n",
    "        maxx = p_class_feature[k]\n",
    "    p_class_feature1[7] = maxx\n",
    "    c=c+1\n",
    "maxx=0\n",
    "c=0\n",
    "for k in range(32,36):\n",
    "    p_class_feature[k] = (p_feature_class[k]*p_class[c])/p_feature[8]\n",
    "    if (p_class_feature[k]>maxx):\n",
    "        maxx = p_class_feature[k]\n",
    "    p_class_feature1[8] = maxx\n",
    "    c=c+1\n",
    "maxx=0\n",
    "c=0\n",
    "for k in range(36,40):\n",
    "    p_class_feature[k] = (p_feature_class[k]*p_class[c])/p_feature[9]\n",
    "    if (p_class_feature[k]>maxx):\n",
    "        maxx = p_class_feature[k]\n",
    "    p_class_feature1[9] = maxx\n",
    "    c=c+1\n",
    "maxx=0\n",
    "c=0\n",
    "for k in range(40,44):\n",
    "    p_class_feature[k] = (p_feature_class[k]*p_class[c])/p_feature[10]\n",
    "    if (p_class_feature[k]>maxx):\n",
    "        maxx = p_class_feature[k]\n",
    "    p_class_feature1[10] = maxx\n",
    "    c=c+1\n",
    "maxx=0\n",
    "c=0\n",
    "for k in range(44,48):\n",
    "    p_class_feature[k] = (p_feature_class[k]*p_class[c])/p_feature[11]\n",
    "    if (p_class_feature[k]>maxx):\n",
    "        maxx = p_class_feature[k]\n",
    "    p_class_feature1[11] = maxx\n",
    "    c=c+1\n",
    "maxx=0\n",
    "c=0\n",
    "for k in range(48,52):\n",
    "    p_class_feature[k] = (p_feature_class[k]*p_class[c])/p_feature[12]\n",
    "    if (p_class_feature[k]>maxx):\n",
    "        maxx = p_class_feature[k]\n",
    "    p_class_feature1[12] = maxx\n",
    "    c=c+1\n",
    "maxx=0\n",
    "c=0\n",
    "for k in range(52,56):\n",
    "    p_class_feature[k] = (p_feature_class[k]*p_class[c])/p_feature[13]\n",
    "    if (p_class_feature[k]>maxx):\n",
    "        maxx = p_class_feature[k]\n",
    "    p_class_feature1[13] = maxx\n",
    "    c=c+1\n",
    "maxx=0\n",
    "c=0\n",
    "for k in range(56,60):\n",
    "    p_class_feature[k] = (p_feature_class[k]*p_class[c])/p_feature[14]\n",
    "    if (p_class_feature[k]>maxx):\n",
    "        maxx = p_class_feature[k]\n",
    "    p_class_feature1[14] = maxx\n",
    "    c=c+1\n",
    "maxx=0\n",
    "c=0\n",
    "for k in range(60,64):\n",
    "    p_class_feature[k] = (p_feature_class[k]*p_class[c])/p_feature[15]\n",
    "    if (p_class_feature[k]>maxx):\n",
    "        maxx = p_class_feature[k]\n",
    "    p_class_feature1[15] = maxx\n",
    "    c=c+1\n",
    "maxx=0\n",
    "c=0\n",
    "for k in range(64,68):\n",
    "    p_class_feature[k] = (p_feature_class[k]*p_class[c])/p_feature[16]\n",
    "    if (p_class_feature[k]>maxx):\n",
    "        maxx = p_class_feature[k]\n",
    "    p_class_feature1[16] = maxx\n",
    "    c=c+1\n",
    "maxx=0\n",
    "c=0\n",
    "for k in range(68,72):\n",
    "    p_class_feature[k] = (p_feature_class[k]*p_class[c])/p_feature[17]\n",
    "    if (p_class_feature[k]>maxx):\n",
    "        maxx = p_class_feature[k]\n",
    "    p_class_feature1[17] = maxx\n",
    "    c=c+1\n",
    "maxx=0\n",
    "c=0\n",
    "for k in range(72,76):\n",
    "    p_class_feature[k] = (p_feature_class[k]*p_class[c])/p_feature[18]\n",
    "    if (p_class_feature[k]>maxx):\n",
    "        maxx = p_class_feature[k]\n",
    "    p_class_feature1[18] = maxx\n",
    "    c=c+1\n",
    "maxx=0\n",
    "c=0\n",
    "for k in range(76,80):\n",
    "    p_class_feature[k] = (p_feature_class[k]*p_class[c])/p_feature[19]\n",
    "    if (p_class_feature[k]>maxx):\n",
    "        maxx = p_class_feature[k]\n",
    "    p_class_feature1[19] = maxx\n",
    "    c=c+1\n",
    "maxx=0\n",
    "c=0\n",
    "for k in range(80,84):\n",
    "    p_class_feature[k] = (p_feature_class[k]*p_class[c])/p_feature[20]\n",
    "    if (p_class_feature[k]>maxx):\n",
    "        maxx = p_class_feature[k]\n",
    "    p_class_feature1[20] = maxx\n",
    "    c=c+1\n",
    "    \n",
    "print(p_class_feature,p_class_feature1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "############################################## FINAL TESTAR FUNCOES #####################################################\n",
    "\n",
    "# p_feature_class[0] = total_el_feature_class[0]/total_el_class[0]\n",
    "# p_feature_class[1] = total_el_feature_class[1]/total_el_class[1]\n",
    "# p_feature_class[2] = total_el_feature_class[2]/total_el_class[2]\n",
    "# p_feature_class[3] = total_el_feature_class[3]/total_el_class[3]\n",
    "\n",
    "# print(total_el_feature_class,p_feature_class,total_el_class)\n",
    "\n",
    "# P(class|atrib) = [P(atri|class)*P(class)]/P(atrib)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'buying'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nhae=dataset.columns\n",
    "type(nhae)\n",
    "nhae[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# IMPLEMENTACAO DO NAIVE BAYES FEITA PELO PROF PARA NUMEROS\n",
    "\n",
    "\n",
    "import csv\n",
    "import math\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    " \n",
    "def loadCsv(filename):\n",
    "    lines = csv.reader(open(filename, \"r\"))\n",
    "    dataset = list(lines)\n",
    "    for i in range(len(dataset)):\n",
    "        dataset[i] = [str(x) for x in dataset[i]]\n",
    "    return dataset    \n",
    "\n",
    "def splitDataset(dataset, splitRatio):\n",
    "    trainSize = int(len(dataset) * splitRatio)\n",
    "    trainSet = []\n",
    "    copy = list(dataset)\n",
    "    \n",
    "    while len(trainSet) < trainSize:\n",
    "        index = random.randrange(len(copy))\n",
    "        trainSet.append(copy.pop(index))\n",
    "    return [trainSet, copy]\n",
    "\n",
    "def separateByClass(dataset):\n",
    "    separated = {}\n",
    "    for i in range(len(dataset)):\n",
    "        vector = dataset[i]\n",
    "        if (vector[-1] not in separated):\n",
    "            separated[vector[-1]] = []\n",
    "        separated[vector[-1]].append(vector)\n",
    "    return separated\n",
    "\n",
    "\n",
    "\n",
    "#### fazer a tabela de probabilidade ######\n",
    "#### FAzer uma contagem ###################\n",
    "\n",
    "\n",
    "def mean(numbers):\n",
    "    return sum(numbers)/float(len(numbers))\n",
    " \n",
    "def stdev(numbers):\n",
    "    avg = mean(numbers)\n",
    "    variance = sum([pow(x-avg,2) for x in numbers])/float(len(numbers)-1)\n",
    "    return math.sqrt(variance)\n",
    "\n",
    "def summarize(dataset):\n",
    "    summaries = [(mean(attribute), stdev(attribute)) for attribute in zip(*dataset)]\n",
    "    del summaries[-1]\n",
    "    #for attribute in zip(*dataset):\n",
    "    #    print(attribute)\n",
    "    return summaries\n",
    "\n",
    "def summarizeByClass(dataset):\n",
    "    separated = separateByClass(dataset)\n",
    "    summaries = {}\n",
    "    for classValue, instances in separated.items():\n",
    "        summaries[classValue] = summarize(instances)\n",
    "    return summaries\n",
    "\n",
    "def calculateProbability(x, mean, stdev):\n",
    "    if(stdev==0):\n",
    "        return 0\n",
    "    exponent = math.exp(-(math.pow(x-mean,2)/(2*math.pow(stdev,2))))\n",
    "    return (1 / (math.sqrt(2*math.pi * math.pow(stdev,2))) * exponent)\n",
    "\n",
    "def calculateClassProbabilities(summaries, inputVector):\n",
    "    probabilities = {}\n",
    "    for classValue, classSummaries in summaries.items():\n",
    "        probabilities[classValue] = 1\n",
    "        for i in range(len(classSummaries)):\n",
    "            mean, stdev = classSummaries[i]\n",
    "            x = inputVector[i]\n",
    "            probabilities[classValue] *= calculateProbability(x, mean, stdev)\n",
    "    return probabilities\n",
    "\n",
    "def predict(summaries, inputVector):\n",
    "    probabilities = calculateClassProbabilities(summaries, inputVector)\n",
    "    bestLabel, bestProb = None, -1\n",
    "    for classValue, probability in probabilities.items():\n",
    "        if bestLabel is None or probability > bestProb:\n",
    "            bestProb = probability\n",
    "            bestLabel = classValue\n",
    "    return bestLabel\n",
    "\n",
    "def getPredictions(summaries, testSet):\n",
    "    predictions = []\n",
    "    for i in range(len(testSet)):\n",
    "        result = predict(summaries, testSet[i])\n",
    "        predictions.append(result)\n",
    "    return predictions\n",
    "\n",
    "def getAccuracy(testSet, predictions):\n",
    "    correct = 0\n",
    "    for i in range(len(testSet)):\n",
    "        if testSet[i][-1] == predictions[i]:\n",
    "            correct += 1\n",
    "    return (correct/float(len(testSet))) * 100.0\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
